{
    "docs": [
        {
            "location": "/", 
            "text": "TiPi framework for solving inverse problems\n\n\nTiPi is a Java \nToolkit for Inverse Problems and Imaging\n developed as part the\n\nMiTiV\n project and supported by the MAGNUM2\nproject.  The objective of TiPi is to provide a framework for developping fast\nalgorithms for solving inverse problems in particular in the domain of imaging.\nTiPi has a number of applications, for instance:\n\n\n\n\n\n\nIn astronomy: TiPi is used for the deblurring and denoising of astronomical\n  images.\n\n\n\n\n\n\nIn the MAGNUM2 project: TiPi is used to repair (inpainting) and enhance\n  (deblurring and denoising) images of license plates before automatic OCR.\n\n\n\n\n\n\nIn microscopy: TiPi is exploited to implement the \ndeconvolution\n and\n  \nblind deconvolution\n plugins of \nIcy\n of\n  3D images.\n\n\n\n\n\n\nContents\n\n\nTiPi provides:\n\n\n\n\n\n\nClasses and methods to manage multi-dimensional arrays, so-called \nshaped\n  arrays\n, in a flexible way.\n\n\n\n\n\n\nClasses and methods to deal with so-called \nvectors\n which\n  stores values in an efficient way.  These vectors are needed by iterative\n  optimization methods and are typically used to store the data, theirs weights\n  and the variables of the inverse problem.\n\n\n\n\n\n\nLimited memory optimization algorithms to deal with large scale non-linear\n  problems possibly with constraints.\n\n\n\n\n\n\nBuilding-block classes to encode objective functions (likelihood,\n  regularization, \netc.\n).\n\n\n\n\n\n\nUtilities for reading or writing data files, \netc.\n\n\n\n\n\n\nRationale and performances issues\n\n\nIn TiPi, data and variable are stored in objects called \nvectors\n\nwhich intentionally have a limited set of methods.  These methods are just\nthose which are needed by optimization algorithms and merely correspond to the\nproperties of vectors in the conventional\n\nlinear algebra sense\n.  Hence the\nname of these objects in TiPi.\n\n\nThanks to these restrictions, \nvectors\n can be implemented in forms suitable\nfor performances (non-conventional or distributed memory, \netc.\n) and a\nparticular implementation is simplified by the fact that only few methods have\nto be exposed (see \nCreating new vector types\n).\n\n\nHowever, \nvectors\n are not really adapted for the many manipulations required\nto prepare the inputs of the algorithms (\ne.g.\n, reading images, converting\ntypes, perform zero-padding, recentering, etc.) and to save the result (e.g.,\nextracting parts, rescaling, writing to a file, \netc.\n).  This is why TiPi\nprovides another type of objects: the \nshaped arrays\n.\nThese objects are much more versatile and use conventional memory.  We were\ncareful so that their manipulation should be very flexible but, as far as\npossible, not to the sacrifice of performances.\n\n\nTypically, an algorithm written in the TiPi framework starts with shaped\narrays, does some pre-processing, then creates vectors from the input arrays,\nruns the iterative method, copies the result into a shaped array, displays\nand/or saves the shaped array, perhaps after some post-processing.\n\n\nA caveat for developpers\n\n\nMany classes in TiPi only differ by the type or rank of the shaped objects\nwhich they implement.  To avoid tedious edition and management of many similar\nsource files, TiPi has its own pre-processor named \ntpp\n\n(\nthe TiPi Pre-processor\n).  The Java code is generated from source\nfiles which have (by convention) the extension \n.javax\n and which are stored in\nthe directory \ntpp\n.  If you want to modify an autogenerated class,\nfirst edit the corresponding \n.javax\n source and then run the command:\n\n\ncd tpp                         # move to tpp directory\n./tpp \nMakefile.x \nMakefile    # generate Makefile if Makefile.x has changed\nmake all                       # make all targets\n\n\n\n\nin the directory \ntpp\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#tipi-framework-for-solving-inverse-problems", 
            "text": "TiPi is a Java  Toolkit for Inverse Problems and Imaging  developed as part the MiTiV  project and supported by the MAGNUM2\nproject.  The objective of TiPi is to provide a framework for developping fast\nalgorithms for solving inverse problems in particular in the domain of imaging.\nTiPi has a number of applications, for instance:    In astronomy: TiPi is used for the deblurring and denoising of astronomical\n  images.    In the MAGNUM2 project: TiPi is used to repair (inpainting) and enhance\n  (deblurring and denoising) images of license plates before automatic OCR.    In microscopy: TiPi is exploited to implement the  deconvolution  and\n   blind deconvolution  plugins of  Icy  of\n  3D images.", 
            "title": "TiPi framework for solving inverse problems"
        }, 
        {
            "location": "/#contents", 
            "text": "TiPi provides:    Classes and methods to manage multi-dimensional arrays, so-called  shaped\n  arrays , in a flexible way.    Classes and methods to deal with so-called  vectors  which\n  stores values in an efficient way.  These vectors are needed by iterative\n  optimization methods and are typically used to store the data, theirs weights\n  and the variables of the inverse problem.    Limited memory optimization algorithms to deal with large scale non-linear\n  problems possibly with constraints.    Building-block classes to encode objective functions (likelihood,\n  regularization,  etc. ).    Utilities for reading or writing data files,  etc.", 
            "title": "Contents"
        }, 
        {
            "location": "/#rationale-and-performances-issues", 
            "text": "In TiPi, data and variable are stored in objects called  vectors \nwhich intentionally have a limited set of methods.  These methods are just\nthose which are needed by optimization algorithms and merely correspond to the\nproperties of vectors in the conventional linear algebra sense .  Hence the\nname of these objects in TiPi.  Thanks to these restrictions,  vectors  can be implemented in forms suitable\nfor performances (non-conventional or distributed memory,  etc. ) and a\nparticular implementation is simplified by the fact that only few methods have\nto be exposed (see  Creating new vector types ).  However,  vectors  are not really adapted for the many manipulations required\nto prepare the inputs of the algorithms ( e.g. , reading images, converting\ntypes, perform zero-padding, recentering, etc.) and to save the result (e.g.,\nextracting parts, rescaling, writing to a file,  etc. ).  This is why TiPi\nprovides another type of objects: the  shaped arrays .\nThese objects are much more versatile and use conventional memory.  We were\ncareful so that their manipulation should be very flexible but, as far as\npossible, not to the sacrifice of performances.  Typically, an algorithm written in the TiPi framework starts with shaped\narrays, does some pre-processing, then creates vectors from the input arrays,\nruns the iterative method, copies the result into a shaped array, displays\nand/or saves the shaped array, perhaps after some post-processing.", 
            "title": "Rationale and performances issues"
        }, 
        {
            "location": "/#a-caveat-for-developpers", 
            "text": "Many classes in TiPi only differ by the type or rank of the shaped objects\nwhich they implement.  To avoid tedious edition and management of many similar\nsource files, TiPi has its own pre-processor named  tpp \n( the TiPi Pre-processor ).  The Java code is generated from source\nfiles which have (by convention) the extension  .javax  and which are stored in\nthe directory  tpp .  If you want to modify an autogenerated class,\nfirst edit the corresponding  .javax  source and then run the command:  cd tpp                         # move to tpp directory\n./tpp  Makefile.x  Makefile    # generate Makefile if Makefile.x has changed\nmake all                       # make all targets  in the directory  tpp .", 
            "title": "A caveat for developpers"
        }, 
        {
            "location": "/framework/", 
            "text": "Basic building blocks in TiPi\n\n\nThe objective of TiPi is to provide a framework for developping fast algorithms\nfor solving inverse problems in particular in the domain of imaging.  In\ngeneral, such problems involve minimization of objective functions with a large\nnumber of variables (\ne.g.\n, as many as the number of pixels in an image or\nvoxels in a volume) by means of iterative methods.  TiPi attempts to address\nthe challenge of achieving efficient computations with large amount of data\nwhile keeping some flexibility to reshape the data and implement various data\nmodel and optimization methods.  For portability reasons, this version of TiPi\nis implemented in Java which has almost the same performances of C/C++ or\nFORTRAN in terms of computations.\n\n\nVectors\n\n\nFor large scale problems, the variables and the data may be stored in many\ndifferent forms (using conventional CPU memory, or GPU memory, or a mixture of\nthese) and they may be split between several machines or shared between several\nprocesses or threads.  Using GPU and/or more more than one CPU is also the way\nto achieve fast computations.  In order to hide this complexity, TiPi assume a\nsimple and minimal interface (in the Java sense) to access the variables and\nthe data of the problem.  This interface consists in a limited (a dozen) number\nof methods which are sufficient to implement all TiPi optimization algorithms.\nIf one has specific memory and computation models, it is sufficient to\nimplement these few required methods to have access to all TiPi algorithms.\n\n\nIt happens that this minimal set of methods merely corresponds to the\nproperties of \nvectors\n in the\nconventional linear algebra sense.  Hence objects implementing these methods\nare also called \nvectors\n in TiPi.  Any concrete (that is instanciable)\nvector type must inherit from the abstract \nVector\n class of TiPi.  In math,\nvectors belong to vector spaces and this is also the case in TiPi where vector\ninstances are owned by instances of vector spaces (whose classes are derived\nfrom the abstract \nVectorSpace\n class).\n\n\nVector manipulations are very simple, for instance assuming \nx\n and \ny\n are\ntwo vectors, then:\n\n\nx.dot(y)\n\n\n\n\nyields the inner product of \nx\n and \ny\n, while:\n\n\nx.add(alpha, y)\n\n\n\n\nadds \nalpha\n (a floating point value) times \ny\n to \nx\n.  Thanks to the fact\nthat vectors are elements of their vector spaces, it is trivial to check\nwhether \nx\n and \ny\n do belong to the same vector space and thus that the above\noperations make sense:\n\n\nif (x.getOwner() != y.getOwner()) {\n    throw new IncorrectSpaceException(\nVectors x and y do not belong to the same vector space\n);\n}\n\n\n\n\nThis is one of the reasons to link vectors to their respective vector space.\nOf course, the above checking is automatically performed by all vector methods\noffered by TiPi which throw an \nIncorrectSpaceException\n exception if\nincompatible vectors are used.\n\n\nTiPi vectors are described in more details in section\n\nUsing vectors\n of the documentation.  The section\n\nCreating new vector types\n is intended for developers\nwho want to implement their own specific type of vectors.\n\n\nShaped arrays\n\n\nVectors in TiPi are easy to implement but do not provide methods for flexible\nmanagement of data and pre- or post-processing.  Thus TiPi provides so-called\n\nshaped arrays\n to manipulate multi-dimensional\n(rectangular) arrays in a more convenient way than vectors.  Of course, TiPi\nprovides means to convert between shaped arrays (designed for easy and flexible\nmanipulation) and vectors (designed for efficiency and intensive computations).\n\n\nA shaped array may have a single or many (up to 9) dimensions and its elements\ncan be any primitive Java numerical type (\nbyte\n, \nshort\n, \nint\n, \nlong\n,\n\nfloat\n or \ndouble\n).  Methods provided with shaped arrays include:\n\n\n\n\n\n\nCreating shaped arrays of different type and shape.\n\n\n\n\n\n\nAddressing the elements of a sub-array individually or via functional\n  mappings or scanners.\n\n\n\n\n\n\nElement type conversion.  For instance \narr.toFloat()\n to convert array\n  \narr\n into an array whose elements are of type \nfloat\n.\n\n\n\n\n\n\nCropping or padding.\n\n\n\n\n\n\nCyclic permutation of elements along the dimensions of the array.\n\n\n\n\n\n\nMaking an image into a shaped array and conversely.\n\n\n\n\n\n\nReading/writing shaped arrays from/to files.\n\n\n\n\n\n\nEfficient sub-array manipulation (slicing, sub-selection, \netc.\n).\n\n\n\n\n\n\nBasic arithmetic or rank reducing operations.\n\n\n\n\n\n\netc.\n\n\n\n\n\n\nSection \nShaped arrays in TiPi\n of the manual describes\nmethods implemented by shaped arrays in more details.  Section\n\nArray factory in TiPi\n of the manual describes how to\ncreate shaped arrays from scratch or from given data.", 
            "title": "Framework"
        }, 
        {
            "location": "/framework/#basic-building-blocks-in-tipi", 
            "text": "The objective of TiPi is to provide a framework for developping fast algorithms\nfor solving inverse problems in particular in the domain of imaging.  In\ngeneral, such problems involve minimization of objective functions with a large\nnumber of variables ( e.g. , as many as the number of pixels in an image or\nvoxels in a volume) by means of iterative methods.  TiPi attempts to address\nthe challenge of achieving efficient computations with large amount of data\nwhile keeping some flexibility to reshape the data and implement various data\nmodel and optimization methods.  For portability reasons, this version of TiPi\nis implemented in Java which has almost the same performances of C/C++ or\nFORTRAN in terms of computations.", 
            "title": "Basic building blocks in TiPi"
        }, 
        {
            "location": "/framework/#vectors", 
            "text": "For large scale problems, the variables and the data may be stored in many\ndifferent forms (using conventional CPU memory, or GPU memory, or a mixture of\nthese) and they may be split between several machines or shared between several\nprocesses or threads.  Using GPU and/or more more than one CPU is also the way\nto achieve fast computations.  In order to hide this complexity, TiPi assume a\nsimple and minimal interface (in the Java sense) to access the variables and\nthe data of the problem.  This interface consists in a limited (a dozen) number\nof methods which are sufficient to implement all TiPi optimization algorithms.\nIf one has specific memory and computation models, it is sufficient to\nimplement these few required methods to have access to all TiPi algorithms.  It happens that this minimal set of methods merely corresponds to the\nproperties of  vectors  in the\nconventional linear algebra sense.  Hence objects implementing these methods\nare also called  vectors  in TiPi.  Any concrete (that is instanciable)\nvector type must inherit from the abstract  Vector  class of TiPi.  In math,\nvectors belong to vector spaces and this is also the case in TiPi where vector\ninstances are owned by instances of vector spaces (whose classes are derived\nfrom the abstract  VectorSpace  class).  Vector manipulations are very simple, for instance assuming  x  and  y  are\ntwo vectors, then:  x.dot(y)  yields the inner product of  x  and  y , while:  x.add(alpha, y)  adds  alpha  (a floating point value) times  y  to  x .  Thanks to the fact\nthat vectors are elements of their vector spaces, it is trivial to check\nwhether  x  and  y  do belong to the same vector space and thus that the above\noperations make sense:  if (x.getOwner() != y.getOwner()) {\n    throw new IncorrectSpaceException( Vectors x and y do not belong to the same vector space );\n}  This is one of the reasons to link vectors to their respective vector space.\nOf course, the above checking is automatically performed by all vector methods\noffered by TiPi which throw an  IncorrectSpaceException  exception if\nincompatible vectors are used.  TiPi vectors are described in more details in section Using vectors  of the documentation.  The section Creating new vector types  is intended for developers\nwho want to implement their own specific type of vectors.", 
            "title": "Vectors"
        }, 
        {
            "location": "/framework/#shaped-arrays", 
            "text": "Vectors in TiPi are easy to implement but do not provide methods for flexible\nmanagement of data and pre- or post-processing.  Thus TiPi provides so-called shaped arrays  to manipulate multi-dimensional\n(rectangular) arrays in a more convenient way than vectors.  Of course, TiPi\nprovides means to convert between shaped arrays (designed for easy and flexible\nmanipulation) and vectors (designed for efficiency and intensive computations).  A shaped array may have a single or many (up to 9) dimensions and its elements\ncan be any primitive Java numerical type ( byte ,  short ,  int ,  long , float  or  double ).  Methods provided with shaped arrays include:    Creating shaped arrays of different type and shape.    Addressing the elements of a sub-array individually or via functional\n  mappings or scanners.    Element type conversion.  For instance  arr.toFloat()  to convert array\n   arr  into an array whose elements are of type  float .    Cropping or padding.    Cyclic permutation of elements along the dimensions of the array.    Making an image into a shaped array and conversely.    Reading/writing shaped arrays from/to files.    Efficient sub-array manipulation (slicing, sub-selection,  etc. ).    Basic arithmetic or rank reducing operations.    etc.    Section  Shaped arrays in TiPi  of the manual describes\nmethods implemented by shaped arrays in more details.  Section Array factory in TiPi  of the manual describes how to\ncreate shaped arrays from scratch or from given data.", 
            "title": "Shaped arrays"
        }, 
        {
            "location": "/shaped-arrays/", 
            "text": "Shaped arrays in TiPi\n\n\nA \nShapedArray\n stores rectangular multi-dimensional arrays of elements of the\nsame data type.  Compared to a \nShapedVector\n, the elements of a \nShapedArray\n\nreside in conventional memory and may be stored in arbitrary order and in a\nnon-contiguous way.\n\n\nClass hierarchy\n\n\nVarious interfaces or abstract classes extend the \nShapedArray\n interface\ndepending on whether the \ntype\n[1]\n and/or the\n\nrank\n[2]\n of the array are unveiled.  The\nnaming conventions are:\n\n\nShapedArray   // neither rank nor type is known\n\nType\nArray   // a shaped array of known type, but any rank\nArray\nRank\nD  // a shaped array of known rank, but any type\n\nType\nRank\nD // a shaped array with known type and rank\n\n\n\n\nwhere the \nType\n field is the capitalized name of the primitive type (\ne.g.\n\n\nDouble\n for \ndouble\n, \nInt\n for \nint\n, \netc.\n) and \nRank\n is a decimal\nnumber in the range 1-9.  Arrays representating scalars are also needed, as\n\n0D\n is a bit odd for 0-rank (that is scalar) object it is replaced by the\nsubstantive \nScalar\n in the rules above for 0-rank arrays and a \nScalar\n\ndenotes a scalar of any type.  For instance:\n\n\n\n\nFloatArray\n is an array of float's;\n\n\nArray3D\n is a three-dimensional array;\n\n\nScalar\n is a scalar of any type;\n\n\nDoubleScalar\n is a 0-rank array to access a single double precision\n  value;\n\n\nLong4D\n is a four-dimensional array of long integer values.\n\n\n\n\nAll these are abstract classes or interfaces, the actual class depends on the\nstorage of the elements of the array.  Most of the time, an array can be\nmanipulated regardless of its concrete class.\n\n\nOperations on shaped arrays\n\n\nThis section describes the operations available for the most basic type, that\nis \nShapedArray\n.\n\n\nBasic operations on shaped arrays\n\n\nThe basic operations available for a \nShapedArray\n, say \narr\n, are the same as\nthose of \nShaped\n and \nTyped\n objects:\n\n\narr.getType()        // query the type of the array\narr.getRank()        // query the rank of the array\narr.getNumber()      // query the number of elements in the array\narr.getDimension(k)  // query the length of the (k+1)-th dimension\narr.getOrder()       // query the storage order of the elements in the array\narr.getShape()       // query the shape of the array\n\n\n\n\nand type conversion:\n\n\narr.toByte()         // convert to ByteArray\narr.toShort()        // convert to ShortArray\narr.toInt()          // convert to IntArray\narr.toLong()         // convert to LongArray\narr.toFloat()        // convert to FloatArray\narr.toDouble()       // convert to DoubleArray\n\n\n\n\nFor efficiency reasons, conversion operations are \nlazzy\n: they return the same\nobject if it is already of the correct type.  Use the \ncopy\n method to\nduplicate an array:\n\n\narr.copy()           // duplicate the contents of the array\n\n\n\n\nThis method yields a new shaped array which has the same shape, type and values\nas \narr\n but whose contents is independent from that of \narr\n.  If \narr\n is a\n\nview\n, then the \ncopy\n method yields a compact array in a \nflat\n[3]\n form.\n\n\nThe elements of a shaped array are generic Java data, their type, as given\nby \narr.getType()\n, can be one of:\n\n\n\n\nTraits.BYTE\n for an array of \nbyte\n elements.\n\n\nTraits.SHORT\n for an array of \nshort\n elements.\n\n\nTraits.INT\n for an array of \nint\n elements.\n\n\nTraits.LONG\n for an array of \nlong\n elements.\n\n\nTraits.FLOAT\n for an array of \nfloat\n elements.\n\n\nTraits.DOUBLE\n for an array of \ndouble\n elements.\n\n\n\n\nThe storage order, as given by \narr.getOrder()\n, indicates how to travel the\nelements of the array for maximum efficiency.  It can be one of:\n\n\n\n\n\n\nShapedArray.COLUMN_MAJOR\n for column-major storage order, that is the\n  leftmost (first) indices vary faster when stepping through consecutive memory\n  locations.\n\n\n\n\n\n\nShapedArray.ROW_MAJOR\n for row-major storage order, that is the rightmost\n  (last) indices vary faster when stepping through consecutive memory\n  locations.\n\n\n\n\n\n\nShapedArray.NONSPECIFIC_ORDER\n for any other storage order.\n\n\n\n\n\n\nAssign elements of a shaped array\n\n\nIt is possible to assign the values of an array from another object:\n\n\narr.assign(src)\n\n\n\n\nwhere \nsrc\n is another shaped array, a shaped vector, or a Java array of a\nprimitive type.  If the type of the elements of \nsrc\n does not match that of\nthe elements of \narr\n, conversion is automatically and silently performed.  If\n\nsrc\n is a \nShaped\n object, its shape must however match that of \narr\n.  If\n\nsrc\n is a Java array, it must have as many elements as \narr\n.  The \nassign\n\noperation is optimized: if \narr\n and \nsrc\n share their contents with the same\nstorage, nothing is done as nothing has to be done.  If \narr\n and \nsrc\n share\ntheir contents in a different form, the result is unpredictable.\n\n\nWhen the type and dimensions of a shaped array are unveiled by its class,\nindividual elements become accessible via its \nget(...)\n and \nset(...)\n\nmethods.\n\n\nCreate a similar shaped array\n\n\nCreating a new array with the same type and shape as \narr\n is simply done by:\n\n\narr.create()\n\n\n\n\nwhich yields a \nflat\n array whose elements are contiguous and stored in\ncolumn-major order.  The \nArrayFactory\n provides static\nmethods to create shaped arrays of any given type and shape (providing the type\nof its elements is known).\n\n\n1D view of a shaped array\n\n\nFinally it is possible to view a shaped array as if it was a mono-dimensional\n(1-D) array.  This is done by:\n\n\narr.as1D()\n\n\n\n\nSince the rank is unveiled by this operation, it is available for any\n\nShapedArray\n and yields an instance of the abstract class \nArray1D\n.  Note\nthat a \nview\n such as the one returned by the \nas1D()\n method let you fetch and\nassign values of the original array with \nget(...)\n and \nset(...)\n methods.\n\n\nOperations available for arrays with unveiled type\n\n\nAdd/subtract/multiply all elements by a scalar:\n\n\narr.increment(value)\narr.decrement(value)\narr.scale(value)\n\n\n\n\nFill with given or generated value:\n\n\narr.fill(value)\narr.fill(generator)\n\n\n\n\nMap a function to every elements:\n\n\narr.map(func)\n\n\n\n\nScan all the elements of the array:\n\n\narr.scan(scanner)\n\n\n\n\nExtract the contents as a flat Java vector:\n\n\narr.flatten([forceCopy])\n\n\n\n\nOther operations\n\n\nFetch a value:\n\n\narr.get(i1,...,iR)\n\n\n\n\nelement type and rank must be known so \narr\n is an instance of some\n\nType\nRank\nD\n abstract class.\n\n\nAssign a value to an element:\n\n\narr.set(i1,...,iR, value)\n\n\n\n\nOperations available for arrays with unveiled rank\n\n\nSlicing\n\n\narr.slice(index[, dim])\n\n\n\n\nBy default \ndim\n = \nLAST\n (-1) to slice through the last dimension, result is\nan array of same data type with one less dimension (slicing a \nFloat3D\n yields\na \nFloat2D\n, slicing a \nDouble1D\n yields a \nDoubleScalar\n, \netc.\n).  The\noperation is fast as it returns a view on \narr\n.  A slice shares its contents\nwith its parent.  The same rules as for ranges (see this section) apply to\n\nindex\n and \ndim\n which can have a negative value understood as being relative\nto the end.\n\n\nRanged sub-array\n\n\nYou can make a sub-array for given ranges of indices:\n\n\narr.view(rng1, rng2, ..., rngR)\n\n\n\n\nwhich returns a view to \narr\n limited to the elements indexed by the\nranges \nrng*\n are either \nRange\n objects or \nnull\n which means\n\"\nall\n\".\n\n\nA range is a construction like:\n\n\nRange rng = new Range(start, stop);\n\n\n\n\nor:\n\n\nRange rng = new Range(start, stop, step);\n\n\n\n\nwhere \nstart\n is the initial index of the range, \nstop\n is the last index and\n\nstep\n is optional and defaults to \n+1\n if omitted.\n\n\nAs in Java, indexes of a range start at \n0\n (also \nRange.FIRST\n) but may be\nnegative.  Starting/ending indexes of a range are interpreted as offsets\nrelative to the length of the dimension of interest if they are strictly\nnegative.  That is \n-1\n (also \nRange.LAST\n) is the last element along a\ndimension, \n-2\n is the penultimate element, \netc.\n This rule is however only\napplied once: if \nj\n is a start/stop index, then \nj\n (if \nj\n \n= 0) or \nj\n+\nn\n\n(if \nj\n \n 0) must be greater or equal 0 and strictly less than \nn\n, the length\nof the dimension of interest.\n\n\nThe convention is that the element corresponding to the first index of a range\nis always considered while the last one may not be reached.  In pseudo-code,\nthe rules are:\n\n\nif (step \n 0) {\n    for (int index = first; index \n= last; index += step) {\n        ...\n    }\n} else if (step \n 0) {\n    for (int index = first; index \n= last; index += step) {\n        ...\n    }\n}\n\n\n\n\nThe sign of the step must be in agreement with the ordering of the first and\nlast element of the range, otherwise the range may be \nempty\n.  This occurs\nwhen (after applying the rules for negative indices) \nfirst\n \n \nlast\n and\n\nstep\n \n 0 and when \nfirst\n \n \nlast\n and \nstep\n \n 0.\n\n\nTo ease the construction of ranges and make the code more readable, we\nrecommend to introduce a range factory in your class, \ne.g.\n:\n\n\nstatic public Range range(int first, int last) {\n    return new Range(first, last);\n}\nstatic public Range range(int first, int last, int step) {\n    return new Range(first, last, step);\n}\n\n\n\n\nThen a ranged view of an array can be written as:\n\n\narr.view(range(0,-1,2), range(4,8))\n\n\n\n\nwhich is lighter and more readable than:\n\n\narr.view(new Range(0,-1,2), new Range(4,8))\n\n\n\n\nSelected sub-array\n\n\nLikewise:\n\n\narr.view(sel1, sel2, ..., selR)\n\n\n\n\nreturns a view to \narr\n from a selection of indices, all \nsel*\n arguments are\neither \nint[]\n index list or \nnull\n which means \nall\n.  Beware that in\nselections of indices, all indices must be reachable (\n-1\n is considered as\nout-of-bounds).\n\n\nTo ease the construction of such views and make the code more readable, you can\nalso use selection factories like:\n\n\nstatic public int[] select(int i1) {\n    return new int[]{i1};\n}\nstatic public int[] select(int i1, int i2) {\n    return new int[]{i1, i2};\n}\nstatic public int[] select(int i1, int i2, int i3) {\n    return new int[]{i1, i2, i3};\n}\n...\n\n\n\n\nand write something like:\n\n\narr.view(select(3,2,9), select(5,1))\n\n\n\n\nNote that sub-arrays and slices are views to the original array (which can\nitself be a view) with fast access to the elements of this array.  If you do\nnot want that the view and its parent share the same elements, use the \ncopy()\n\nmethod after making the view.\n\n\nIt is currently not possible to mix ranges, slicing and index selection in a\nsingle sub-array construction, as it would result in too many possibilities\n(and potentially inefficient code).  It is however possible to chain\nsub-array-constructions to obtain the same effect.  For instance:\n\n\narr.view(null, range(2,11,3)).view(select(6,4,8,2), null)\n\n\n\n\nto mimic:\n\n\narr.view(select(6,4,8,2), range(2,11,3))\n\n\n\n\nwhich is not allowed for now.\n\n\n[1] Type:\n The primitive type of the elements of a \nTyped\n object.\n\n\u21a9\n\n\n[2] Rank:\n The number of dimensions of a multi-dimensional\n(a.k.a. \nshaped\n) object. \n\u21a9\n\n\n[3] Flat:\n Zero-offset, contiguous storage in column-major order.\n\n\u21a9", 
            "title": "Shaped Arrays"
        }, 
        {
            "location": "/shaped-arrays/#shaped-arrays-in-tipi", 
            "text": "A  ShapedArray  stores rectangular multi-dimensional arrays of elements of the\nsame data type.  Compared to a  ShapedVector , the elements of a  ShapedArray \nreside in conventional memory and may be stored in arbitrary order and in a\nnon-contiguous way.", 
            "title": "Shaped arrays in TiPi"
        }, 
        {
            "location": "/shaped-arrays/#class-hierarchy", 
            "text": "Various interfaces or abstract classes extend the  ShapedArray  interface\ndepending on whether the  type [1]  and/or the rank [2]  of the array are unveiled.  The\nnaming conventions are:  ShapedArray   // neither rank nor type is known Type Array   // a shaped array of known type, but any rank\nArray Rank D  // a shaped array of known rank, but any type Type Rank D // a shaped array with known type and rank  where the  Type  field is the capitalized name of the primitive type ( e.g.  Double  for  double ,  Int  for  int ,  etc. ) and  Rank  is a decimal\nnumber in the range 1-9.  Arrays representating scalars are also needed, as 0D  is a bit odd for 0-rank (that is scalar) object it is replaced by the\nsubstantive  Scalar  in the rules above for 0-rank arrays and a  Scalar \ndenotes a scalar of any type.  For instance:   FloatArray  is an array of float's;  Array3D  is a three-dimensional array;  Scalar  is a scalar of any type;  DoubleScalar  is a 0-rank array to access a single double precision\n  value;  Long4D  is a four-dimensional array of long integer values.   All these are abstract classes or interfaces, the actual class depends on the\nstorage of the elements of the array.  Most of the time, an array can be\nmanipulated regardless of its concrete class.", 
            "title": "Class hierarchy"
        }, 
        {
            "location": "/shaped-arrays/#operations-on-shaped-arrays", 
            "text": "This section describes the operations available for the most basic type, that\nis  ShapedArray .", 
            "title": "Operations on shaped arrays"
        }, 
        {
            "location": "/shaped-arrays/#basic-operations-on-shaped-arrays", 
            "text": "The basic operations available for a  ShapedArray , say  arr , are the same as\nthose of  Shaped  and  Typed  objects:  arr.getType()        // query the type of the array\narr.getRank()        // query the rank of the array\narr.getNumber()      // query the number of elements in the array\narr.getDimension(k)  // query the length of the (k+1)-th dimension\narr.getOrder()       // query the storage order of the elements in the array\narr.getShape()       // query the shape of the array  and type conversion:  arr.toByte()         // convert to ByteArray\narr.toShort()        // convert to ShortArray\narr.toInt()          // convert to IntArray\narr.toLong()         // convert to LongArray\narr.toFloat()        // convert to FloatArray\narr.toDouble()       // convert to DoubleArray  For efficiency reasons, conversion operations are  lazzy : they return the same\nobject if it is already of the correct type.  Use the  copy  method to\nduplicate an array:  arr.copy()           // duplicate the contents of the array  This method yields a new shaped array which has the same shape, type and values\nas  arr  but whose contents is independent from that of  arr .  If  arr  is a view , then the  copy  method yields a compact array in a  flat [3]  form.  The elements of a shaped array are generic Java data, their type, as given\nby  arr.getType() , can be one of:   Traits.BYTE  for an array of  byte  elements.  Traits.SHORT  for an array of  short  elements.  Traits.INT  for an array of  int  elements.  Traits.LONG  for an array of  long  elements.  Traits.FLOAT  for an array of  float  elements.  Traits.DOUBLE  for an array of  double  elements.   The storage order, as given by  arr.getOrder() , indicates how to travel the\nelements of the array for maximum efficiency.  It can be one of:    ShapedArray.COLUMN_MAJOR  for column-major storage order, that is the\n  leftmost (first) indices vary faster when stepping through consecutive memory\n  locations.    ShapedArray.ROW_MAJOR  for row-major storage order, that is the rightmost\n  (last) indices vary faster when stepping through consecutive memory\n  locations.    ShapedArray.NONSPECIFIC_ORDER  for any other storage order.", 
            "title": "Basic operations on shaped arrays"
        }, 
        {
            "location": "/shaped-arrays/#assign-elements-of-a-shaped-array", 
            "text": "It is possible to assign the values of an array from another object:  arr.assign(src)  where  src  is another shaped array, a shaped vector, or a Java array of a\nprimitive type.  If the type of the elements of  src  does not match that of\nthe elements of  arr , conversion is automatically and silently performed.  If src  is a  Shaped  object, its shape must however match that of  arr .  If src  is a Java array, it must have as many elements as  arr .  The  assign \noperation is optimized: if  arr  and  src  share their contents with the same\nstorage, nothing is done as nothing has to be done.  If  arr  and  src  share\ntheir contents in a different form, the result is unpredictable.  When the type and dimensions of a shaped array are unveiled by its class,\nindividual elements become accessible via its  get(...)  and  set(...) \nmethods.", 
            "title": "Assign elements of a shaped array"
        }, 
        {
            "location": "/shaped-arrays/#create-a-similar-shaped-array", 
            "text": "Creating a new array with the same type and shape as  arr  is simply done by:  arr.create()  which yields a  flat  array whose elements are contiguous and stored in\ncolumn-major order.  The  ArrayFactory  provides static\nmethods to create shaped arrays of any given type and shape (providing the type\nof its elements is known).", 
            "title": "Create a similar shaped array"
        }, 
        {
            "location": "/shaped-arrays/#1d-view-of-a-shaped-array", 
            "text": "Finally it is possible to view a shaped array as if it was a mono-dimensional\n(1-D) array.  This is done by:  arr.as1D()  Since the rank is unveiled by this operation, it is available for any ShapedArray  and yields an instance of the abstract class  Array1D .  Note\nthat a  view  such as the one returned by the  as1D()  method let you fetch and\nassign values of the original array with  get(...)  and  set(...)  methods.", 
            "title": "1D view of a shaped array"
        }, 
        {
            "location": "/shaped-arrays/#operations-available-for-arrays-with-unveiled-type", 
            "text": "Add/subtract/multiply all elements by a scalar:  arr.increment(value)\narr.decrement(value)\narr.scale(value)  Fill with given or generated value:  arr.fill(value)\narr.fill(generator)  Map a function to every elements:  arr.map(func)  Scan all the elements of the array:  arr.scan(scanner)  Extract the contents as a flat Java vector:  arr.flatten([forceCopy])", 
            "title": "Operations available for arrays with unveiled type"
        }, 
        {
            "location": "/shaped-arrays/#other-operations", 
            "text": "Fetch a value:  arr.get(i1,...,iR)  element type and rank must be known so  arr  is an instance of some Type Rank D  abstract class.  Assign a value to an element:  arr.set(i1,...,iR, value)", 
            "title": "Other operations"
        }, 
        {
            "location": "/shaped-arrays/#operations-available-for-arrays-with-unveiled-rank", 
            "text": "", 
            "title": "Operations available for arrays with unveiled rank"
        }, 
        {
            "location": "/shaped-arrays/#slicing", 
            "text": "arr.slice(index[, dim])  By default  dim  =  LAST  (-1) to slice through the last dimension, result is\nan array of same data type with one less dimension (slicing a  Float3D  yields\na  Float2D , slicing a  Double1D  yields a  DoubleScalar ,  etc. ).  The\noperation is fast as it returns a view on  arr .  A slice shares its contents\nwith its parent.  The same rules as for ranges (see this section) apply to index  and  dim  which can have a negative value understood as being relative\nto the end.", 
            "title": "Slicing"
        }, 
        {
            "location": "/shaped-arrays/#ranged-sub-array", 
            "text": "You can make a sub-array for given ranges of indices:  arr.view(rng1, rng2, ..., rngR)  which returns a view to  arr  limited to the elements indexed by the\nranges  rng*  are either  Range  objects or  null  which means\n\" all \".  A range is a construction like:  Range rng = new Range(start, stop);  or:  Range rng = new Range(start, stop, step);  where  start  is the initial index of the range,  stop  is the last index and step  is optional and defaults to  +1  if omitted.  As in Java, indexes of a range start at  0  (also  Range.FIRST ) but may be\nnegative.  Starting/ending indexes of a range are interpreted as offsets\nrelative to the length of the dimension of interest if they are strictly\nnegative.  That is  -1  (also  Range.LAST ) is the last element along a\ndimension,  -2  is the penultimate element,  etc.  This rule is however only\napplied once: if  j  is a start/stop index, then  j  (if  j   = 0) or  j + n \n(if  j    0) must be greater or equal 0 and strictly less than  n , the length\nof the dimension of interest.  The convention is that the element corresponding to the first index of a range\nis always considered while the last one may not be reached.  In pseudo-code,\nthe rules are:  if (step   0) {\n    for (int index = first; index  = last; index += step) {\n        ...\n    }\n} else if (step   0) {\n    for (int index = first; index  = last; index += step) {\n        ...\n    }\n}  The sign of the step must be in agreement with the ordering of the first and\nlast element of the range, otherwise the range may be  empty .  This occurs\nwhen (after applying the rules for negative indices)  first     last  and step    0 and when  first     last  and  step    0.  To ease the construction of ranges and make the code more readable, we\nrecommend to introduce a range factory in your class,  e.g. :  static public Range range(int first, int last) {\n    return new Range(first, last);\n}\nstatic public Range range(int first, int last, int step) {\n    return new Range(first, last, step);\n}  Then a ranged view of an array can be written as:  arr.view(range(0,-1,2), range(4,8))  which is lighter and more readable than:  arr.view(new Range(0,-1,2), new Range(4,8))", 
            "title": "Ranged sub-array"
        }, 
        {
            "location": "/shaped-arrays/#selected-sub-array", 
            "text": "Likewise:  arr.view(sel1, sel2, ..., selR)  returns a view to  arr  from a selection of indices, all  sel*  arguments are\neither  int[]  index list or  null  which means  all .  Beware that in\nselections of indices, all indices must be reachable ( -1  is considered as\nout-of-bounds).  To ease the construction of such views and make the code more readable, you can\nalso use selection factories like:  static public int[] select(int i1) {\n    return new int[]{i1};\n}\nstatic public int[] select(int i1, int i2) {\n    return new int[]{i1, i2};\n}\nstatic public int[] select(int i1, int i2, int i3) {\n    return new int[]{i1, i2, i3};\n}\n...  and write something like:  arr.view(select(3,2,9), select(5,1))  Note that sub-arrays and slices are views to the original array (which can\nitself be a view) with fast access to the elements of this array.  If you do\nnot want that the view and its parent share the same elements, use the  copy() \nmethod after making the view.  It is currently not possible to mix ranges, slicing and index selection in a\nsingle sub-array construction, as it would result in too many possibilities\n(and potentially inefficient code).  It is however possible to chain\nsub-array-constructions to obtain the same effect.  For instance:  arr.view(null, range(2,11,3)).view(select(6,4,8,2), null)  to mimic:  arr.view(select(6,4,8,2), range(2,11,3))  which is not allowed for now.  [1] Type:  The primitive type of the elements of a  Typed  object. \u21a9  [2] Rank:  The number of dimensions of a multi-dimensional\n(a.k.a.  shaped ) object.  \u21a9  [3] Flat:  Zero-offset, contiguous storage in column-major order. \u21a9", 
            "title": "Selected sub-array"
        }, 
        {
            "location": "/array-factory/", 
            "text": "The array factory in TiPi\n\n\nThe class \nArrayFactory\n provides static methods for creating new shaped\narrays, converting arrays to have a specific element type or wrap existing\nobjects in a shaped array which share its elements with the object.\n\n\nCreate a new shaped array\n\n\nThe static method \nArrayFactory.create()\n creates a shaped array with given\nelement type and shape.  There are many possibilities to specify the shape of\nthe array, for instance:\n\n\nArrayFactory.create(type, shape)\nArrayFactory.create(type, dims)\nArrayFactory.create(type, dim1, dim2, ...)\n\n\n\n\nwhere \ntype\n is the element type, \nshape\n is the array shape (an instance of\n\nShape\n), \ndims\n is an \nint[]\n array with the list of dimensions, \ndim1\n,\n\ndim2\n ... are the successive dimensions.  Shaped arrays may have up to 9\ndimensions (which is probably too large for any reasonnable application).\n\n\nNo dimensions may be specified in order to create a scalar of a given type:\n\n\nArrayFactory.create(type)\n\n\n\n\nThe array element type can be one of:\n\n\n\n\nTraits.BYTE\n for an array of \nbyte\n elements;\n\n\nTraits.SHORT\n for an array of \nshort\n elements;\n\n\nTraits.INT\n for an array of \nint\n elements;\n\n\nTraits.LONG\n for an array of \nlong\n elements;\n\n\nTraits.FLOAT\n for an array of \nfloat\n elements;\n\n\nTraits.DOUBLE\n for an array of \ndouble\n elements.\n\n\n\n\nThe storage of the elements of an array created by \nArrayFactory.create(...)\n\nis provided by a simple monodimensional Java array with the same element type.\nFor multi-dimensional arrays, the storage order of arrays created by\n\nArrayFactory.create(...)\n is \ncolum-major\n which means that the leftmost\n(first) indices vary faster when stepping through consecutive memory locations.\n\n\nWrap an array around existing data\n\n\nA shaped array may be created to share its elements with an existing\nmonodimensional Java array of any generic numerical type.  This is done by one\nof the \nArrayFactory.wrap(...)\n methods as follows:\n\n\nArrayFactory.wrap(buf, shape)\nArrayFactory.wrap(buf, dims)\nArrayFactory.wrap(buf, dim1, dim2, ...)\n\n\n\n\nwhere \nbuf\n is the Java array and the same notation as above is used for\nspecifying the list of dimensions.  The length of the buffer \nbuf\n must be the\nsame as the number of elements of the resulting shaped array (the product of\nits dimensions).  The constructors of the \nStridden\nType\nRank\nD\n classes can\nbe used to wrap shaped arrays with arbitrary strides and offsets around\nmonodimensional Java arrays.\n\n\nA single element buffer can be wrapped into a scalar by:\n\n\nArrayFactory.wrap(buf)\n\n\n\n\nAny shaped vector, say \nvec\n, can also be wrapped into a shaped array as\nfollows:\n\n\nArrayFactory.wrap(vec)\n\n\n\n\nwhich yieds a \nShapedArray\n if \nvec\n is a \nShapedVector\n and a\n\nFloatShapedArray\n or a \nDoubleShapedArray\n if \nvec\n is a \nFloatShapedVector\n\nor a \nDoubleShapedVector\n respectively.  The type and shape of the resulting\narray are the same as those of \nvec\n and it is guaranteed that they share their\ncontents (with contiguous elements in colum-major order).  So the resulting\nshaped array can be seen as a \nview\n of the shaped vector.\n\n\nType conversion\n\n\nThe element type af an existing array can be converted by one of the\n\nto\nType\n()\n methods.  For instance:\n\n\nArrayFactory.toFloat(arr)\narr.toFloat()\n\n\n\n\nboth yield a version of \narr\n whose elements are of generic type \nfloat\n.  For\nmaximum efficiency, the conversion operation is \nlazzy\n in the sense that the\nsame array is returned if it already has the requested type.\n\n\nWarning:\n In a near futur, static methods like \nArrayFactory.toFloat(arr)\n\nwill be deprecated in favor of instance methods like \narr.toFloat()\n which\nare more readable.", 
            "title": "Making Arrays"
        }, 
        {
            "location": "/array-factory/#the-array-factory-in-tipi", 
            "text": "The class  ArrayFactory  provides static methods for creating new shaped\narrays, converting arrays to have a specific element type or wrap existing\nobjects in a shaped array which share its elements with the object.", 
            "title": "The array factory in TiPi"
        }, 
        {
            "location": "/array-factory/#create-a-new-shaped-array", 
            "text": "The static method  ArrayFactory.create()  creates a shaped array with given\nelement type and shape.  There are many possibilities to specify the shape of\nthe array, for instance:  ArrayFactory.create(type, shape)\nArrayFactory.create(type, dims)\nArrayFactory.create(type, dim1, dim2, ...)  where  type  is the element type,  shape  is the array shape (an instance of Shape ),  dims  is an  int[]  array with the list of dimensions,  dim1 , dim2  ... are the successive dimensions.  Shaped arrays may have up to 9\ndimensions (which is probably too large for any reasonnable application).  No dimensions may be specified in order to create a scalar of a given type:  ArrayFactory.create(type)  The array element type can be one of:   Traits.BYTE  for an array of  byte  elements;  Traits.SHORT  for an array of  short  elements;  Traits.INT  for an array of  int  elements;  Traits.LONG  for an array of  long  elements;  Traits.FLOAT  for an array of  float  elements;  Traits.DOUBLE  for an array of  double  elements.   The storage of the elements of an array created by  ArrayFactory.create(...) \nis provided by a simple monodimensional Java array with the same element type.\nFor multi-dimensional arrays, the storage order of arrays created by ArrayFactory.create(...)  is  colum-major  which means that the leftmost\n(first) indices vary faster when stepping through consecutive memory locations.", 
            "title": "Create a new shaped array"
        }, 
        {
            "location": "/array-factory/#wrap-an-array-around-existing-data", 
            "text": "A shaped array may be created to share its elements with an existing\nmonodimensional Java array of any generic numerical type.  This is done by one\nof the  ArrayFactory.wrap(...)  methods as follows:  ArrayFactory.wrap(buf, shape)\nArrayFactory.wrap(buf, dims)\nArrayFactory.wrap(buf, dim1, dim2, ...)  where  buf  is the Java array and the same notation as above is used for\nspecifying the list of dimensions.  The length of the buffer  buf  must be the\nsame as the number of elements of the resulting shaped array (the product of\nits dimensions).  The constructors of the  Stridden Type Rank D  classes can\nbe used to wrap shaped arrays with arbitrary strides and offsets around\nmonodimensional Java arrays.  A single element buffer can be wrapped into a scalar by:  ArrayFactory.wrap(buf)  Any shaped vector, say  vec , can also be wrapped into a shaped array as\nfollows:  ArrayFactory.wrap(vec)  which yieds a  ShapedArray  if  vec  is a  ShapedVector  and a FloatShapedArray  or a  DoubleShapedArray  if  vec  is a  FloatShapedVector \nor a  DoubleShapedVector  respectively.  The type and shape of the resulting\narray are the same as those of  vec  and it is guaranteed that they share their\ncontents (with contiguous elements in colum-major order).  So the resulting\nshaped array can be seen as a  view  of the shaped vector.", 
            "title": "Wrap an array around existing data"
        }, 
        {
            "location": "/array-factory/#type-conversion", 
            "text": "The element type af an existing array can be converted by one of the to Type ()  methods.  For instance:  ArrayFactory.toFloat(arr)\narr.toFloat()  both yield a version of  arr  whose elements are of generic type  float .  For\nmaximum efficiency, the conversion operation is  lazzy  in the sense that the\nsame array is returned if it already has the requested type.  Warning:  In a near futur, static methods like  ArrayFactory.toFloat(arr) \nwill be deprecated in favor of instance methods like  arr.toFloat()  which\nare more readable.", 
            "title": "Type conversion"
        }, 
        {
            "location": "/vectors/", 
            "text": "Using vectors in TiPi\n\n\nThis section describes the objects used in TiPi to store the variables (but\nalso the data and their weights) of an optimization problem.\n\n\nOperations involving vector spaces\n\n\nVectors can be created by their vector space with either undefined contents of\nwith their components set to given values.  For instance, to create a new\nvector of the vector space \nvsp\n:\n\n\nvsp.create()    // yields a new vector with undefined contents\nvsp.create(val) // yields a new vector with all components set to `val`\nvsp.one()       // is equivalent to space.create(1)\nvsp.zero()      // is equivalent to space.create(0)\n\n\n\n\nTo check whether a vector \nvec\n belongs to the vector space \nvsp\n, the\nfollowing expressions can be used:\n\n\nvsp.owns(vec)\nvec.belongsTo(vsp)\nvec.getOwner() == vsp\n\n\n\n\nThe call:\n\n\nvsp.check(vec)\n\n\n\n\nchecks whether vector \nvec\n belongs to the vector space \nvsp\n and throws an\n\nIncorrectSpaceException\n exception otherwise.\n\n\nMethods implemented by vectors\n\n\nMany methods are available to directly manipulate vectors.  These methods are\nsufficient to implement the iterative optimization algorithms provided by TiPi.\n\n\nThe following methods are assumed to be efficient:\n\n\n\n\n\n\nvec.create()\n yields a new vector of the same vector space as \nvec\n\n  with undefined contents.\n\n\n\n\n\n\nvec.clone()\n yields a new vector of the same vector space as \nvec\n and with\n  all its components set to the corresponding values of the components of\n  \nvec\n.\n\n\n\n\n\n\ndst.copy(src)\n copies the values of the components of vector \nsrc\n into\n  vector \ndst\n.\n\n\n\n\n\n\nvec.norm2()\n yields the Euclidean norm of \nvec\n which is the square root of\n  the sum of the squared value of its components.\n\n\n\n\n\n\nvec.norm1()\n yields the L1 norm of \nvec\n which is the sum of the absolute\n  value of its components.\n\n\n\n\n\n\nvec.norm2()\n yields the infinite norm of \nvec\n which is the maximum absolute\n  value of its components.\n\n\n\n\n\n\nx.dot(y)\n yields the dot product of vectors \nx\n and \ny\n.\n\n\n\n\n\n\nw.dot(x,y)\n yields the dot product of vectors \nx\n and \ny\n weighted by \nw\n.\n  This dot product can be expressed as \nx'.W.y\n where \nW = diag(w)\n is a\n  diagonal weighting operator.\n\n\n\n\n\n\nx.swap(y)\n exchanges the values of the corresponding components of vectors\n  \nx\n and \ny\n.\n\n\n\n\n\n\nvec.fill(val)\n set all components of vector \nvec\n to the value \nval\n.\n\n\n\n\n\n\nvec.zero()\n is the same as \nx.fill(0)\n\n\n\n\n\n\nVarious linear combination of vectors can be formed:\n\n\n\n\n\n\ndst.add(alpha, x)\n add to the components of \ndst\n the components of the\n  vector \nx\n multiplied by the scalar \nalpha\n.\n\n\n\n\n\n\ndst.combine(alpha, x, beta, y)\n stores in \ndst\n the sum of \nalpha\n times \nx\n\n  plus \nbeta\n times \ny\n.\n\n\n\n\n\n\ndst.combine(alpha, x, beta, y, gamma, z)\n\n\n\n\n\n\nvec.scale(val)\n scales all the components of the vector \nvec\n by the scalar\n  \nalpha\n\n\n\n\n\n\ndst.scale(alpha, src)\n stores in vector \ndst\n the result of scaling vector\n  \nsrc\n by the scalar \nalpha\n.\n\n\n\n\n\n\ndst.multiply(w)\n stores in vector \ndst\n the result of the component-wise\n  multiplication of \ndst\n by the vector \nw\n.\n\n\n\n\n\n\ndst.multiply(w, x)\n stores in vector \ndst\n the result of the component-wise\n  multiplication of vectors \nw\n and \nx\n.\n\n\n\n\n\n\nThe above methods manipulate vectors globally are supposed to be efficient.\nTwo methods are provided to examine or set individually the components of a\nvector.  These methods are mainly used for debugging or informative purposes\nand are not meant to be efficient (although it does not hurt if they are!).\n\n\n\n\n\n\nvec.get(i)\n get the value of \ni\n-th component of vector \nvec\n.\n\n\n\n\n\n\nvec.set(i, val)\n set the \ni\n-th component of vector \nvec\n to the value \nval\n.\n\n\n\n\n\n\nwhere index \ni\n is an integer between \n0\n for the first component and \nn - 1\n\nfor the last component (\nn\n being the number of components of the vector).\n\n\n\n\n\n\nvec.getNumber()\n and \nvec.length()\n yields the number of components of the\n  vector \nvec\n.\n\n\n\n\n\n\nvec.getOwner()\n and \nvec.getSpace()\n yields the vector space to which\n  belongs vector \nvec\n.", 
            "title": "Vectors"
        }, 
        {
            "location": "/vectors/#using-vectors-in-tipi", 
            "text": "This section describes the objects used in TiPi to store the variables (but\nalso the data and their weights) of an optimization problem.", 
            "title": "Using vectors in TiPi"
        }, 
        {
            "location": "/vectors/#operations-involving-vector-spaces", 
            "text": "Vectors can be created by their vector space with either undefined contents of\nwith their components set to given values.  For instance, to create a new\nvector of the vector space  vsp :  vsp.create()    // yields a new vector with undefined contents\nvsp.create(val) // yields a new vector with all components set to `val`\nvsp.one()       // is equivalent to space.create(1)\nvsp.zero()      // is equivalent to space.create(0)  To check whether a vector  vec  belongs to the vector space  vsp , the\nfollowing expressions can be used:  vsp.owns(vec)\nvec.belongsTo(vsp)\nvec.getOwner() == vsp  The call:  vsp.check(vec)  checks whether vector  vec  belongs to the vector space  vsp  and throws an IncorrectSpaceException  exception otherwise.", 
            "title": "Operations involving vector spaces"
        }, 
        {
            "location": "/vectors/#methods-implemented-by-vectors", 
            "text": "Many methods are available to directly manipulate vectors.  These methods are\nsufficient to implement the iterative optimization algorithms provided by TiPi.  The following methods are assumed to be efficient:    vec.create()  yields a new vector of the same vector space as  vec \n  with undefined contents.    vec.clone()  yields a new vector of the same vector space as  vec  and with\n  all its components set to the corresponding values of the components of\n   vec .    dst.copy(src)  copies the values of the components of vector  src  into\n  vector  dst .    vec.norm2()  yields the Euclidean norm of  vec  which is the square root of\n  the sum of the squared value of its components.    vec.norm1()  yields the L1 norm of  vec  which is the sum of the absolute\n  value of its components.    vec.norm2()  yields the infinite norm of  vec  which is the maximum absolute\n  value of its components.    x.dot(y)  yields the dot product of vectors  x  and  y .    w.dot(x,y)  yields the dot product of vectors  x  and  y  weighted by  w .\n  This dot product can be expressed as  x'.W.y  where  W = diag(w)  is a\n  diagonal weighting operator.    x.swap(y)  exchanges the values of the corresponding components of vectors\n   x  and  y .    vec.fill(val)  set all components of vector  vec  to the value  val .    vec.zero()  is the same as  x.fill(0)    Various linear combination of vectors can be formed:    dst.add(alpha, x)  add to the components of  dst  the components of the\n  vector  x  multiplied by the scalar  alpha .    dst.combine(alpha, x, beta, y)  stores in  dst  the sum of  alpha  times  x \n  plus  beta  times  y .    dst.combine(alpha, x, beta, y, gamma, z)    vec.scale(val)  scales all the components of the vector  vec  by the scalar\n   alpha    dst.scale(alpha, src)  stores in vector  dst  the result of scaling vector\n   src  by the scalar  alpha .    dst.multiply(w)  stores in vector  dst  the result of the component-wise\n  multiplication of  dst  by the vector  w .    dst.multiply(w, x)  stores in vector  dst  the result of the component-wise\n  multiplication of vectors  w  and  x .    The above methods manipulate vectors globally are supposed to be efficient.\nTwo methods are provided to examine or set individually the components of a\nvector.  These methods are mainly used for debugging or informative purposes\nand are not meant to be efficient (although it does not hurt if they are!).    vec.get(i)  get the value of  i -th component of vector  vec .    vec.set(i, val)  set the  i -th component of vector  vec  to the value  val .    where index  i  is an integer between  0  for the first component and  n - 1 \nfor the last component ( n  being the number of components of the vector).    vec.getNumber()  and  vec.length()  yields the number of components of the\n  vector  vec .    vec.getOwner()  and  vec.getSpace()  yields the vector space to which\n  belongs vector  vec .", 
            "title": "Methods implemented by vectors"
        }, 
        {
            "location": "/devel/", 
            "text": "Notes for developers\n\n\nEclipse\n\n\nExternal libraries\n\n\nCopy the JAR file(s) of the external libraries in \nlib\n directory, then\n\nRefresh\n the Project and in \nProject Properties\n, choose \nJava Build Path\n,\ntab \nLibraries\n and hit \nAdd JARs...\n.  Then browse in the \nlib\n directory of\nthe project and select the JAR file.\n\n\nIt is then possible to attach source and documentation for the JAR library file\nby expanding its entry in the list (the small black arrow at the left of its\nname).\n\n\nAnt scripts\n\n\nJava, Ant and JavadDoc must be installed:\n\n\nsudo apt install ant\nsudo apt install default-jdk\n\n\n\nIn \nExport\n choose \nGeneral \n Ant Buildfiles\n select \nTiPi\n.\n\n\nDocumentation\n\n\nDocumentation consists in JavaDoc automatically generated from the Java source\nand manual pages written in MarkDown format (in the \ndocs\n directory) and\npublished using \nMkDocs\n.\n\n\nInstallation of MkDocs\n\n\nMkDocs\n can be installed by PIP:\n\n\nsudo apt install python-pip python-setuptools\nsudo pip install --upgrade mkdoc\n\n\n\nEditing the documentation\n\n\nWhile editing the files in the \ndocs\n directory, you can have a look at the\nresult by using the built-in server of MkDocs and opening URL\nhttp://127.0.0.1:8000 with your browser.  To launch the server:\n\n\nmkdocs serve\n\n\n\nwhile in the directory where is the \nmkdocs.yml\n file (above the \ndocs\n\ndirectory).  To generate manually the documentation, type (from the same\ndirectory):\n\n\nmkdocs build --clean\n\n\n\nPublishing the documentation\n\n\nTo publish the doc:\n\n\nmkdocs gh-deploy --clean", 
            "title": "Code Maintenance"
        }, 
        {
            "location": "/devel/#notes-for-developers", 
            "text": "", 
            "title": "Notes for developers"
        }, 
        {
            "location": "/devel/#eclipse", 
            "text": "", 
            "title": "Eclipse"
        }, 
        {
            "location": "/devel/#external-libraries", 
            "text": "Copy the JAR file(s) of the external libraries in  lib  directory, then Refresh  the Project and in  Project Properties , choose  Java Build Path ,\ntab  Libraries  and hit  Add JARs... .  Then browse in the  lib  directory of\nthe project and select the JAR file.  It is then possible to attach source and documentation for the JAR library file\nby expanding its entry in the list (the small black arrow at the left of its\nname).", 
            "title": "External libraries"
        }, 
        {
            "location": "/devel/#ant-scripts", 
            "text": "Java, Ant and JavadDoc must be installed:  sudo apt install ant\nsudo apt install default-jdk  In  Export  choose  General   Ant Buildfiles  select  TiPi .", 
            "title": "Ant scripts"
        }, 
        {
            "location": "/devel/#documentation", 
            "text": "Documentation consists in JavaDoc automatically generated from the Java source\nand manual pages written in MarkDown format (in the  docs  directory) and\npublished using  MkDocs .", 
            "title": "Documentation"
        }, 
        {
            "location": "/devel/#installation-of-mkdocs", 
            "text": "MkDocs  can be installed by PIP:  sudo apt install python-pip python-setuptools\nsudo pip install --upgrade mkdoc", 
            "title": "Installation of MkDocs"
        }, 
        {
            "location": "/devel/#editing-the-documentation", 
            "text": "While editing the files in the  docs  directory, you can have a look at the\nresult by using the built-in server of MkDocs and opening URL\nhttp://127.0.0.1:8000 with your browser.  To launch the server:  mkdocs serve  while in the directory where is the  mkdocs.yml  file (above the  docs \ndirectory).  To generate manually the documentation, type (from the same\ndirectory):  mkdocs build --clean", 
            "title": "Editing the documentation"
        }, 
        {
            "location": "/devel/#publishing-the-documentation", 
            "text": "To publish the doc:  mkdocs gh-deploy --clean", 
            "title": "Publishing the documentation"
        }, 
        {
            "location": "/new-vector-types/", 
            "text": "Creating new vector types in TiPi\n\n\nFor now TiPi only provides two concrete types of vectors, \nDoubleShapedVector\n\nand \nFlaotShapedVector\n, with their respective vector spaces classes,\n\nDoubleShapedVectorSpace\n and \nFloatShapedVectorSpace\n.  Such vectors store\ntheir components in a single Java array of type \ndouble[]\n or \nfloat[]\n and are\nclosely connected to \nShapedArray\n (\ni.e.\n, they also have a \nshape\n).  For\nvery large problems, it may be more convenient to store the components of the\nvectors differently, perhaps on different machines and/or in GPU memory.  It is\npossible (and hopefully easy) to make TiPi aware of this specific storage by\nimplementing the corresponding vector and vector space classes.  Another reason\nto create a new vector and vector space type may be to provide more efficient\n(\ne.g.\n, multi-threaded) versions of the methods designed to operate on\nvectors.\n\n\nImplementing a new type of vectors in TiPi involves two things:\n\n\n\n\n\n\nA concrete sub-class of \nVector\n for the vectors of this vector space.  This\n   can be as simple as implementing the two methods \nget()\n and \nset()\n for\n   getting and setting a specific component of a vector.  These methods are not\n   meant to be efficient, they are mainly provided for testing or debugging\n   purposes.\n\n\n\n\n\n\nA concrete sub-class of \nVectorSpace\n for the vector space.  Only a dozen of\n   methods which operate on the specifc vectors of this vector space have to be\n   implemented.  These methods are assumed to be efficient and are used by TiPi\n   to perform all necessary operations on vectors.\n\n\n\n\n\n\nAll methods whose name begins with an underscore character, \ne.g.\n \n_dot\n, are\nlow-level \nprotected\n methods which must not be directly called by the\nend-user.  They are used by higher level methods which take care of checking\nthe validity of the arguments, in particular that the vectors belong to the\ncorrect vector space.  Thus in the implementation of these low level methods no\nargument checking is necessary.\n\n\nEven though vectors can use any type of floating point values to store their\ncomponents, all scalar values in TiPi are passed as double precision floating\npoint.\n\n\nMethods that must be overridden\n\n\nA concrete implementation of the \nVector\n class has to override the following\nmethods:\n\n\n\n\n\n\nMethod \npublic double get(int i) throws IndexOutOfBoundsException\n yields\n  the value of the component at index \ni\n of the vector.\n\n\n\n\n\n\nMethod \npublic void set(int i, double val) throws IndexOutOfBoundsException\n\n  set the component at index \ni\n of the vector to the value \nval\n.\n\n\n\n\n\n\nAs said before, these two methods are not meant to be efficient, they are\nmainly provided for testing or debugging purposes.  This is not the case for\nthe methods of the concrete implementation of the \nVectorSpace\n class described\nbelow.\n\n\nA concrete implementation of the \nVectorSpace\n class has to override the\nfollowing mandatory methods:\n\n\n\n\n\n\nMethod \npublic Vector create()\n creates a new vector of the vector space with\n  undefined contents.\n\n\n\n\n\n\nMethod \nprotected void _swap(Vector x, Vector y)\n exchange the contents of\n  the two vectors \nx\n and \ny\n.\n\n\n\n\n\n\nMethod \nprotected void _fill(Vector vec, double alpha)\n set all components of\n  vector \nvec\n to the value \nalpha\n.\n\n\n\n\n\n\nMethod \nprotected void _scale(Vector dst, double alpha, Vector src)\n for\n  scaling the components of vector \nsrc\n by the scalar \nalpha\n and store the\n  result in vector \ndst\n.\n\n\n\n\n\n\nMethod \nprotected double _dot(Vector x, Vector y)\n computes the inner\n  product of the two vectors \nx\n and \ny\n, that is the sum of the products of\n  the corresponding components of the two vectors.\n\n\n\n\n\n\nMethod \nprotected double _dot(Vector w, Vector x, Vector y)\n computes the\n  inner product of three vectors or the weighted inner product of two vectors.\n\n\n\n\n\n\nMethod \nprotected double _norm1(Vector x)\n computes the L1 norm of the vector\n  \nx\n, that is the sum of absolute values of the components of \nx\n.\n\n\n\n\n\n\nMethod \nprotected double _normInf(Vector x)\n computes the infinite norm of\n  the vector \nx\n, that is the maximum absolute value of the components of \nx\n.\n\n\n\n\n\n\nMethod \nprotected void _multiply(Vector dst, Vector x, Vector y)\n performs a\n  component-wise multiplication of two vectors: \ndst[i] = x[i]*y[i]\n (for all\n  \ni\n).  This method is used to implement diagonal operators.\n\n\n\n\n\n\nMethod \nprotected void _combine(Vector dst, double alpha, Vector x, double\n  beta, Vector y)\n computes the linear combination of two vectors: \ndst[i] =\n  alpha*x[i] + beta*x[i]\n (for all \ni\n).  As this method can be used to emulate\n  other operations (as \ncopy\n, \nzero\n, \netc.\n), actual code should be optimized\n  for specific factors \nalpha\n and/or \nbeta\n equal to +/-1 or 0.  In particular\n  when \nalpha\n (resp. \nbeta\n) is zero, then \nx\n (resp. \ny\n) must not be\n  referenced.\n\n\n\n\n\n\nMethod \nprotected void _combine(Vector dst, double alpha, Vector x, double\n  beta, Vector y, double gamma, Vector z)\n computes the linear combination of\n  three vectors: \ndst[i] = alpha*x[i] + beta*x[i] + gamma*z[i]\n (for all \ni\n).\n  As this method can be used to emulate other operations (as \ncopy\n, \nzero\n,\n  \netc.\n), actual code should be optimized for specific factors \nalpha\n and/or\n  \nbeta\n equal to +/-1 or 0.  In particular when \nalpha\n (resp. \nbeta\n or\n  \ngamma\n) is zero, then \nx\n (resp. \ny\n or \nz\n) must not be referenced.\n\n\n\n\n\n\nMethods with default implementation\n\n\nThe following methods have a default implementation which can be overridden\nwith more efficient versions by the descendants of the \nVectorSpace\n abstract\nclass:\n\n\n\n\nMethod \nprotected double _norm2(Vector x)\n computes the Euclidean (L2) norm\n  of the vector \nx\n, that is the square root of the sum of squared components\n  of \nx\n.  The following default implementation is provided:\n\n\n\n\nprotected double _norm2(Vector x) {\n    return Math.sqrt(_dot(x, x));\n}\n\n\n\n\n\n\nMethod \nprotected void _scale(Vector vec, double alpha)\n for in-place scaling\n  of vector \nvec\n by the scalar \nalpha\n has the following default\n  implementation:\n\n\n\n\nprotected void _scale(Vector vec, double alpha) {\n    _scale(vec, alpha, vec);\n}\n\n\n\n\n\n\nMethod \nprotected void _copy(Vector dst, Vector src)\n copies the contents of\n  a vector into another one: \ndst[i] = src[i]\n (for all \ni\n) with the following\n  default implementation:\n\n\n\n\nprotected void _copy(Vector dst, Vector src) {\n    _combine(dst, 1, src, 0, src);\n}\n\n\n\n\n\n\nMethod \nprotected Vector _clone(Vector vec)\n creates a new vector as a clone\n  of another vector, it has the following default implementation:\n\n\n\n\nprotected Vector _clone(Vector vec) {\n    Vector cpy = create();\n    _copy(cpy, vec);\n    return cpy;\n}\n\n\n\n\n\n\nMethod \nprotected void _zero(Vector vec)\n to set to zero all components of\n  vector \nvec\n has the following default implementation:\n\n\n\n\nprotected void _zero(Vector vec) {\n    _fill(vec, 0);\n}\n\n\n\n\n\n\nMethod \nprotected void _add(Vector dst, double alpha, Vector x)\n adds \nalpha\n\n  times \nx\n to \ndst\n: \ndst[i] += alpha*x[i]\n and has the following default\n  implementation:\n\n\n\n\nprotected void _add(Vector dst, double alpha, Vector x) {\n    _combine(dst, 1, dst, alpha, x);\n}", 
            "title": "New Vector Types"
        }, 
        {
            "location": "/new-vector-types/#creating-new-vector-types-in-tipi", 
            "text": "For now TiPi only provides two concrete types of vectors,  DoubleShapedVector \nand  FlaotShapedVector , with their respective vector spaces classes, DoubleShapedVectorSpace  and  FloatShapedVectorSpace .  Such vectors store\ntheir components in a single Java array of type  double[]  or  float[]  and are\nclosely connected to  ShapedArray  ( i.e. , they also have a  shape ).  For\nvery large problems, it may be more convenient to store the components of the\nvectors differently, perhaps on different machines and/or in GPU memory.  It is\npossible (and hopefully easy) to make TiPi aware of this specific storage by\nimplementing the corresponding vector and vector space classes.  Another reason\nto create a new vector and vector space type may be to provide more efficient\n( e.g. , multi-threaded) versions of the methods designed to operate on\nvectors.  Implementing a new type of vectors in TiPi involves two things:    A concrete sub-class of  Vector  for the vectors of this vector space.  This\n   can be as simple as implementing the two methods  get()  and  set()  for\n   getting and setting a specific component of a vector.  These methods are not\n   meant to be efficient, they are mainly provided for testing or debugging\n   purposes.    A concrete sub-class of  VectorSpace  for the vector space.  Only a dozen of\n   methods which operate on the specifc vectors of this vector space have to be\n   implemented.  These methods are assumed to be efficient and are used by TiPi\n   to perform all necessary operations on vectors.    All methods whose name begins with an underscore character,  e.g.   _dot , are\nlow-level  protected  methods which must not be directly called by the\nend-user.  They are used by higher level methods which take care of checking\nthe validity of the arguments, in particular that the vectors belong to the\ncorrect vector space.  Thus in the implementation of these low level methods no\nargument checking is necessary.  Even though vectors can use any type of floating point values to store their\ncomponents, all scalar values in TiPi are passed as double precision floating\npoint.", 
            "title": "Creating new vector types in TiPi"
        }, 
        {
            "location": "/new-vector-types/#methods-that-must-be-overridden", 
            "text": "A concrete implementation of the  Vector  class has to override the following\nmethods:    Method  public double get(int i) throws IndexOutOfBoundsException  yields\n  the value of the component at index  i  of the vector.    Method  public void set(int i, double val) throws IndexOutOfBoundsException \n  set the component at index  i  of the vector to the value  val .    As said before, these two methods are not meant to be efficient, they are\nmainly provided for testing or debugging purposes.  This is not the case for\nthe methods of the concrete implementation of the  VectorSpace  class described\nbelow.  A concrete implementation of the  VectorSpace  class has to override the\nfollowing mandatory methods:    Method  public Vector create()  creates a new vector of the vector space with\n  undefined contents.    Method  protected void _swap(Vector x, Vector y)  exchange the contents of\n  the two vectors  x  and  y .    Method  protected void _fill(Vector vec, double alpha)  set all components of\n  vector  vec  to the value  alpha .    Method  protected void _scale(Vector dst, double alpha, Vector src)  for\n  scaling the components of vector  src  by the scalar  alpha  and store the\n  result in vector  dst .    Method  protected double _dot(Vector x, Vector y)  computes the inner\n  product of the two vectors  x  and  y , that is the sum of the products of\n  the corresponding components of the two vectors.    Method  protected double _dot(Vector w, Vector x, Vector y)  computes the\n  inner product of three vectors or the weighted inner product of two vectors.    Method  protected double _norm1(Vector x)  computes the L1 norm of the vector\n   x , that is the sum of absolute values of the components of  x .    Method  protected double _normInf(Vector x)  computes the infinite norm of\n  the vector  x , that is the maximum absolute value of the components of  x .    Method  protected void _multiply(Vector dst, Vector x, Vector y)  performs a\n  component-wise multiplication of two vectors:  dst[i] = x[i]*y[i]  (for all\n   i ).  This method is used to implement diagonal operators.    Method  protected void _combine(Vector dst, double alpha, Vector x, double\n  beta, Vector y)  computes the linear combination of two vectors:  dst[i] =\n  alpha*x[i] + beta*x[i]  (for all  i ).  As this method can be used to emulate\n  other operations (as  copy ,  zero ,  etc. ), actual code should be optimized\n  for specific factors  alpha  and/or  beta  equal to +/-1 or 0.  In particular\n  when  alpha  (resp.  beta ) is zero, then  x  (resp.  y ) must not be\n  referenced.    Method  protected void _combine(Vector dst, double alpha, Vector x, double\n  beta, Vector y, double gamma, Vector z)  computes the linear combination of\n  three vectors:  dst[i] = alpha*x[i] + beta*x[i] + gamma*z[i]  (for all  i ).\n  As this method can be used to emulate other operations (as  copy ,  zero ,\n   etc. ), actual code should be optimized for specific factors  alpha  and/or\n   beta  equal to +/-1 or 0.  In particular when  alpha  (resp.  beta  or\n   gamma ) is zero, then  x  (resp.  y  or  z ) must not be referenced.", 
            "title": "Methods that must be overridden"
        }, 
        {
            "location": "/new-vector-types/#methods-with-default-implementation", 
            "text": "The following methods have a default implementation which can be overridden\nwith more efficient versions by the descendants of the  VectorSpace  abstract\nclass:   Method  protected double _norm2(Vector x)  computes the Euclidean (L2) norm\n  of the vector  x , that is the square root of the sum of squared components\n  of  x .  The following default implementation is provided:   protected double _norm2(Vector x) {\n    return Math.sqrt(_dot(x, x));\n}   Method  protected void _scale(Vector vec, double alpha)  for in-place scaling\n  of vector  vec  by the scalar  alpha  has the following default\n  implementation:   protected void _scale(Vector vec, double alpha) {\n    _scale(vec, alpha, vec);\n}   Method  protected void _copy(Vector dst, Vector src)  copies the contents of\n  a vector into another one:  dst[i] = src[i]  (for all  i ) with the following\n  default implementation:   protected void _copy(Vector dst, Vector src) {\n    _combine(dst, 1, src, 0, src);\n}   Method  protected Vector _clone(Vector vec)  creates a new vector as a clone\n  of another vector, it has the following default implementation:   protected Vector _clone(Vector vec) {\n    Vector cpy = create();\n    _copy(cpy, vec);\n    return cpy;\n}   Method  protected void _zero(Vector vec)  to set to zero all components of\n  vector  vec  has the following default implementation:   protected void _zero(Vector vec) {\n    _fill(vec, 0);\n}   Method  protected void _add(Vector dst, double alpha, Vector x)  adds  alpha \n  times  x  to  dst :  dst[i] += alpha*x[i]  and has the following default\n  implementation:   protected void _add(Vector dst, double alpha, Vector x) {\n    _combine(dst, 1, dst, alpha, x);\n}", 
            "title": "Methods with default implementation"
        }, 
        {
            "location": "/tpp/", 
            "text": "The TiPi Pre-processor\n\n\nTPP\n, the \nTiPi Pre-processor\n, is used to produce Java code of many TiPi\nclasses from a single or a few source files.  In TiPi source tree, the files\nwhich need to be pre-processed by TPP to produce Java code are suffixed by\n\n.javax\n and are all in the \ntpp\n directory.\n\n\nThe principles of TPP are simple: it interprets special pre-processor\ndirectives in the source code and re-emit other lines of code, possibly several\ntimes if these lines appear in a pre-processor loop, after performing macro\nsubstitution.  Compared to other programming language pre-processors, TPP\nprovides macros with immediate and deferred substitution, loops, evaluation of\nexpressions and can be used to generate almost arbitrary code.\n\n\nCalling the Preprocessor\n\n\nThe syntax for calling TPP is:\n\n\ntpp [OPTIONS] [INPUT [OUTPUT]]\n\n\n\n\nto preprocess the source file \nINPUT\n and produce the destination file\n\nOUTPUT\n.  If omitted or set to \n-\n, the source (resp. the destination) file is\nthe standard input (resp.the standard output).\n\n\nOptions in \nOPTIONS\n are:\n\n\n\n\n\n\n-Dname=value\n: Define a macro (there may be many options of this kind).\n\n\n\n\n\n\n-a\n or \n--autopkg\n: Guess the Java package from the name of the output file\n  and define a macro named \npackage\n with the package name and whose value will\n  replace all occurrences of \n${package}\n in the processed code.\n\n\n\n\n\n\n-f\n or \n--docfilter\n: Filter JavaDoc comments for unused parameters.\n\n\n\n\n\n\n--debug\n: Turn debug mode on.\n\n\n\n\n\n\n-h\n, \n-?\n or \n--help\n: Print a short help message and exit.\n\n\n\n\n\n\n-v\n or \n--version\n: Print version number and exit.\n\n\n\n\n\n\n-w\n or \n--warning\n: Add a warning on top of the file to prevent editing the\n  result.\n\n\n\n\n\n\n--\n: Indicate the end of the options.\n\n\n\n\n\n\nSome options are clearly targeted at Java code, but TPP can be applied to\nother programming languages.\n\n\nGeneral Syntax\n\n\nPre-processor directives are lines of the form:\n\n\n//# COMMAND ...\n\n\n\n\nwhere, to improve readability, there can be any spaces before \n//\n, before and\nafter \n#\n.  In the output, all lines matching this and with a recognized\n\nCOMMAND\n are omitted.\n\n\nAll commands can have and optional comment which is delimited by the first\noccurrence of \n//\n after the \n//#\n:\n\n\n//# COMMAND ... // COMMENT\n\n\n\n\nBoth \nCOMMAND\n and \nCOMMENT\n may be empty.  Comment lines are a special case\nwith an empty \nCOMMAND\n and empty lines like:\n\n\n//#\n\n\n\n\nhave only spaces (including none) after the \n#\n and are ignored.\n\n\nMacros\n\n\nMacros are pre-processor variables associated with a value.  Every occurrences\nof something like \n${NAME}\n in the code will be replaced by the actual value of\nthe macro whose name is \nNAME\n.  It is an error if \nNAME\n is not a defined\nmacro.  Macro substitution is recursive: all occurrences of \n${...}\n are\nreplaced by the corresponding value in the processed file until no other\nsubstitutions are possible.  The name of a macro is case sensitive, it starts\nwith a Latin letter or an underscore character (\na\n to \nz\n, \nA\n to \nZ\n or \n_\n)\nwhich can be followed by any number of Latin letters, underscore characters or\ndigits (\n0\n to \n9\n).\n\n\nA macro can be redefined (unless it is one of the\n\nread-only macros\n) and can be undefined at any time.  It\nis also possible to temporarily suspend and resume substitution of a specific\nmacro.\n\n\nSimple Macro Definition\n\n\nThe \ndef\n command defines a macro and takes one of the two following forms:\n\n\n//# def NAME  = VALUE // COMMENT\n//# def NAME := VALUE // COMMENT\n\n\n\n\nwhere \nNAME\n is the name of the macro, \nVALUE\n specifies the macro value and\n\nCOMMENT\n is an optional comment.  The \nVALUE\n term may be empty to define the\nmacro to be an empty string.  Spaces after the assignment operator and after\nthe \nVALUE\n term are ignored.\n\n\nThe two possibilities for (re)defining a macro differ in the processing of the\n\nVALUE\n term:\n\n\n\n\n\n\nIf the assignment operator is \n=\n, then all macros are recursively\n  substituted in the \nVALUE\n term before defining the macro \nNAME\n.\n\n\n\n\n\n\nIf the assignment operator is \n:=\n, then substitutions in the \nVALUE\n term\n  are deferred until \n${NAME}\n is expanded except that occurrences of \n${NAME}\n\n  in the \nVALUE\n term are substituted.  This exception is to avoid infinite\n  substitution loops but can be exploited to append or prepend stuff to an\n  existing macro.  This is of interest when a macro is build piece by piece in\n  a loop for instance.  As explained later, this \nfeature\n can also be used to\n  \nmimic macros with arguments\n.\n\n\n\n\n\n\nNote that contrarily to C preprocessor, overwritting an existing definition is\nnot forbidden.\n\n\nEvaluate a Numerical Expression\n\n\nA macro can be defined by evaluating a numerical expression with the directive:\n\n\n//# eval NAME OPER EXPR\n\n\n\n\nwhere \nNAME\n is the macro name, \nOPER\n is an assignment operator and \nEXPR\n a\nnumerical expression whose value is computed before (re)defining \nNAME\n via the\noperator.\n\n\nThe expression in \nEXPR\n is evaluated after recursive macro substitution.  The\nsyntax of the expression is similar to that of the C (in fact it is implemented\nby the \nexpr\n command of Tcl) with a special function \ndefined(MACRO)\n which\nyields \ntrue\n or \nfalse\n depending whether \nMACRO\n is a defined macro or not.\n\n\nThe operator \nOPER\n can be a simple \n=\n to assign the result of evaluating\nexpression \nEXPR\n to the macro \nNAME\n or a composite operator like \nOP=\n to\nassign to \nNAME\n the result of the expression \n${NAME} OP (EXPR)\n where \nOP\n\ncan be \n+\n, \n-\n, \n*\n, \n/\n, \n%\n, \n or \n.\n\n\nExample:\n\n\n//# def a = 1\n//# def b = 4\n//# eval a += ${b}/2\n\n\n\n\nyields a macro named \na\n whose value is \n3\n.\n\n\nExpressions involve integer arithmetic and tests:\n\n\n\n\ndefined(NAME)\n       check whether macro \nNAME\n is defined;\n\n\n! defined(NAME)\n     check whether macro \nNAME\n is not defined;\n\n\nEXPR1 || EXPR2\n      logical \nor\n (with lazzy evaluation);\n\n\nEXPR1 \n EXPR2\n      logical \nand\n (with lazzy evaluation);\n\n\n\"text\"\n              literal text for string comparison;\n\n\n\n\nNote that macros are recursively substituted if they appear in an expression\nincluding whithin the double quotes of a string.\n\n\nPredefined Macros\n\n\nWhen processing a file, TPP automatically define (and update) the following\nmacros:\n\n\n\n\n${__FILE__}\n yields the name of the current processed file.\n\n\n${__LINE__}\n yields the current line number in the processed file.\n\n\n${__NEWLINE__}\n yields a newline character: \"\\n\".\n\n\n${__SPACE__}\n yields a single space character: \" \".\n\n\n${__COMMENT__}\n yields the comment delimiter.\n\n\n${}\n yields an ordinary dollar sign.\n\n\n\n\nThese macros are read-only and cannot be redefined.\n\n\nMacros can also be defined at the command line with the argument \n-Dname=value\n\nwhere \nname\n is the name of the macro and \nvalue\n its initial value.  There may\nbe as many such definitions in the command line as needed.\n\n\nUndefine Macros\n\n\nThe command:\n\n\n//# undef NAME1 NAME2 ...\n\n\n\n\nundefines the macros \nNAME1\n, \nNAME2\n, etc.  Until they are redefined, it is an\nerror to expand these macros.  Read-only macros cannot be undefined.\nUndefining a macro which is not defined does nothing.\n\n\nSuspend Macro Expansion\n\n\nThe \n#def\n directive with the \n:=\n operator only partially expands the value of\na macro.  While this is sufficient for most of the cases, it is sometimes\nnecessary (or more readable) to temporally suspend the expansion of some\nmacros.\n\n\nThe command:\n\n\n//# suspend NAME1 NAME2 ...\n\n\n\n\nsuspends the expansion of the macros \nNAME1\n, \nNAME2\n, etc.  Until these macros\nare redefined or their expansion resumed with the \n#resume\n directive, they\nwill not be expanded.  For instance, the expansion of \n${NAME1}\n will produce\n\n${NAME1}\n.  Note that it is not required that a macro be defined prior to\nsuspend its expansion.\n\n\nAs said before, defining a macro (by the \n#def\n or \n#eval\n or \n#for\n\ndirectives) resume the expansion of the macro.  This can also be achieved with\nthe following directive:\n\n\n//# resume NAME1 NAME2 ...\n\n\n\n\nConditional Branching\n\n\nA block of code can be processed or not depending on a logical test using the\n\n#if\n directive and related \n#elif\n and \n#else\n directives.  The syntax is as\nfollows (with an arbitrary number, including none, of \n#elif\n directives and at\nmost one \n#else\n directive):\n\n\n//# if EXPR1\nBLOCK1\n//# elif EXPR2\nBLOCK2\n//# else\nBLOCK3\n//# end\n\n\n\n\nwhere \nBLOCK1\n is processed if \nEXPR1\n evaluates to \ntrue\n, otherwise \nBLOCK2\n\nis processed if \nEXPR2\n evaluates to \ntrue\n, eventually \nBLOCK3\n is processed\nif neither \nEXPR1\n nor \nEXPR2\n evaluate to \ntrue\n.  Conditional expressions are\nevaluated using the same rules as in the \n#eval\n directive.\n\n\nLoops\n\n\nA distinctive feature of TPP is to provide loops which may be embedded in other\nloops to an arbitrarily level.  There are two kinds of loops: \nfor\n-loops and\n\nwhile\n-loops.\n\n\nThe syntax of a \nfor\n-loop is:\n\n\n//# for NAME in EXPR\n...\n//# end\n\n\n\n\nwhere \nEXPR\n is everything after the \nin\n keyword and up to the end of line or\nto the \n//\n of the optional comment.  After macro substitution of the \nEXPR\n\nterm, it is interpreted either as a list of values separated by spaces or as a\nrange.  The macro \nNAME\n will successively takes the different values of the\nlist or of the range and the body of the loop (that is code up to the matching\n\nend\n keyword) will be processed.  If, after macro substitutions, the value of\n\nEXPR\n is an empty list or an empty range, the the body of the loop is just\nskipped.\n\n\nA range of values has the form:\n\n\nFIRST : LAST\n\n\n\n\nor\n\n\nFIRST : LAST : STEP\n\n\n\n\nwhere (after macro expansion) \nFIRST\n, \nLAST\n and \nSTEP\n are integers, if\nomitted, \nSTEP\n is assumed to be \n1\n.  A zero-\nSTEP\n is forbidden.  Numerical\nexpressions are not yet supported for these fields but you can use the \n#eval\n\ndirective to compute the range parameters.  For instance:\n\n\n//# eval last = ${x} + 3*${y}\n//# for i in 0 : ${last} // main loop\n...\n//# end // end of main loop\n\n\n\n\nHere is another example with a list of values:\n\n\n//# def list = blue red yellow orange\n//# for var in ${list}\n//#     emit ${var}\n//# end\n\n\n\n\nwhere the directive \n#emit\n directive emits its argument(s) in the output code.\n\n\nThe syntax of \nwhile\n-loops is:\n\n\n//# while EXPR\n...\n//# end\n\n\n\n\nwhich results in processing the boby of the loop until \nEXPR\n expands to a\nfalse value.\n\n\nThe two following loops are similar (the second being more concise):\n\n\n//# def body := dim${k} = ${k}; // the code to expand\n//# def k = 4\n//# while ${k} \n 12\n${boby}\n//#     eval k += 3\n//# end\n\n//# def body := dim${k} = ${k};\n//# for k in 4:12:3\n${body}\n//# end\n\n\n\n\nthey both produce:\n\n\ndim4 = 4\ndim7 = 7\ndim10 = 10\n\n\n\n\nNote how the expansion of \n${k}\n is deferred by using operator \n:=\n to define\nmacro \nbody\n.\n\n\nInclude Another Source File\n\n\nThe contents of another source file can be processed at any place by using the\n\n#include\n directive:\n\n\n//# include WHAT\n\n\n\n\nwhere \nWHAT\n (after recursive macro expansion) takes one of the two forms:\n\nFILENAME\n or \n\"FILENAME\"\n.  The result is as if the contents of the file\n\nFILENAME\n be inserted in place of the command.  A restriction is that\ndirectives operating on blocks (\n#if ...\n, \n#for ...\n and \n#while ...\n) must\nbe open and closed in a single included file.\n\n\nEmitting Code or Printing Messages\n\n\nThe command:\n\n\n//# emit CODE\n\n\n\n\nsubstitutes macros in \nCODE\n and prints it to the output file.\n\n\nCommands:\n\n\n//# echo MESG\n//# warn MESG\n\n\n\n\nsubstitute macros in \nMESG\n and print it.  Command \n#echo\n uses the standard\noutput stream while \n#warn\n uses the standard error stream.\n\n\nIt may be useful to examine the contents of some macros (without a fully\nrecursive expansion).  To that end, the directive\n\n\n//# debug MESG\n\n\n\n\nprints \nMESG\n after a \nsingle round\n of macro substitution on the standard error\nstream.\n\n\nThe \n#error\n command:\n\n\n//# error MESG\n\n\n\n\nsubstitutes macros in \nMESG\n and prints it on the standard error stream with\nthe line number and the name of the processed file and then aborts the\nprocessing.\n\n\nExamples\n\n\nVariable Length Lists\n\n\nThe following example builds a list of dimensions:\n\n\n//# def dims =  // start with an empty list\n//# def sep  =  // and an empty separator\n//# for k in 1 : ${rank}\n//#     def dims = ${dims}${sep}dim${k}\n//#     def sep = ,${__SPACE__}\n//# end\n\n\n\n\nand yields a macro named \ndims\n with contents \ndim1, dim2, ...\n.  Note the use\nof an auxiliary macro \nsep\n and of the predefined macro \n__SPACE__\n to nicely\nseparate the elements of the list.  Another possibility is to write:\n\n\n//# if ${rank} \n 1\n//#     def dims =  // result is an empty list\n//# else\n//#     def dims = dim1 // initial list\n//#     for k in 2 : ${rank}\n//#         def dims = ${dims}, dim${k}\n//#     end\n//# end\n\n\n\n\nMacros as Pseudo-Functions\n\n\nDeferred substitution can be used as follows:\n\n\n//# def list := ${prefix}1\n//# for k in 2 : 3\n//#     def list := ${list},${prefix}${k}\n//# end\n\n\n\n\nwhich yields a macro \nlist\n whose contents is\n\n${prefix}1,${prefix}2,${prefix}3\n.  Note that, at this stage, \nprefix\n does\nnot need to be defined.  The macro \nlist\n can then be used as a template to\nmake lists after substitution of the \nprefix\n macro:\n\n\n//# def prefix  = foo\n//# def FooList = ${list}\n//# def prefix  = bar\n//# def BarList = ${list}\n\n\n\nwhich yields `foo1,foo2,foo3` and `bar1,bar2,bar3` for the respective contents\nof macros `FooList` and `BarList`.\n\nWith this kind of trick it is also possible to mimic the behavior of\nmacros with arguments (even though it is less readable).\n\nTo build the macro `list` above, we may also suspend the expansion of the macro\n`prefix`:\n\n```java\n//# suspend prefix\n//# def list = ${prefix}1\n//# for k in 2 : 3\n//#     def list = ${list},${prefix}${k}\n//# end\n\n\n\n\nAs (re)defining \nprefix\n will automatically resume macro expansion, it is not\nnecessary to have a \n#resume prefix\n command.\n\n\nIndex of Directives\n\n\n\n\n\n\n//\n comment;\n\n\n\n\n\n\n#debug\n print a debug message;\n\n\n\n\n\n\n#def\n define a macro;\n\n\n\n\n\n\n#echo\n print a message to the\n  standard output stream;\n\n\n\n\n\n\n#elif\n conditional branching;\n\n\n\n\n\n\n#else\n conditional branching;\n\n\n\n\n\n\n#emit\n write some code to the result;\n\n\n\n\n\n\n#end\n mark the end of a loop or of a conditional\n  branching;\n\n\n\n\n\n\n#error\n output an error message and\n  exit;\n\n\n\n\n\n\n#eval\n evaluate a numerical expression;\n\n\n\n\n\n\n#for\n loop with a macro taking different values;\n\n\n\n\n\n\n#if\n conditional branching;\n\n\n\n\n\n\n#include\n include the contents of another\n  file;\n\n\n\n\n\n\n#resume\n resume macro expansion;\n\n\n\n\n\n\n#suspend\n suspend macro expansion;\n\n\n\n\n\n\n#undef\n undefine a macro;\n\n\n\n\n\n\n#warn\n print a message to the\n  standard error stream;\n\n\n\n\n\n\n#while\n conditional loop;\n\n\n\n\n\n\nFuture Evolution\n\n\n\n\n\n\nIt may be useful to customize the syntax in order to accomodate to\n   various programming languages.  For instance:\n\n\n\n\n\n\n@name@\n       to interpolate a macro;\n\n\n\n\n@@\n           for a single \n@\n;\n\n\n\n\n#@ COMMAND\n   for preprocessor directives;\n\n\n\n\n\n\nMacros with arguments (spaces stripped): \n${macro(arg1,arg2,...)}\n\n\n\n\n\n\nString functions (like predefined macros).\n\n\n\n\n\n\n${substr(str,i1,i2,subs)}\n${strmatch(string,pattern)}\n...\n\n\n\n\n\n\nAllow for numerical expressions in ranges (taking care of the ternary\n   operator).", 
            "title": "The TiPi Preprocessor"
        }, 
        {
            "location": "/tpp/#the-tipi-pre-processor", 
            "text": "TPP , the  TiPi Pre-processor , is used to produce Java code of many TiPi\nclasses from a single or a few source files.  In TiPi source tree, the files\nwhich need to be pre-processed by TPP to produce Java code are suffixed by .javax  and are all in the  tpp  directory.  The principles of TPP are simple: it interprets special pre-processor\ndirectives in the source code and re-emit other lines of code, possibly several\ntimes if these lines appear in a pre-processor loop, after performing macro\nsubstitution.  Compared to other programming language pre-processors, TPP\nprovides macros with immediate and deferred substitution, loops, evaluation of\nexpressions and can be used to generate almost arbitrary code.", 
            "title": "The TiPi Pre-processor"
        }, 
        {
            "location": "/tpp/#calling-the-preprocessor", 
            "text": "The syntax for calling TPP is:  tpp [OPTIONS] [INPUT [OUTPUT]]  to preprocess the source file  INPUT  and produce the destination file OUTPUT .  If omitted or set to  - , the source (resp. the destination) file is\nthe standard input (resp.the standard output).  Options in  OPTIONS  are:    -Dname=value : Define a macro (there may be many options of this kind).    -a  or  --autopkg : Guess the Java package from the name of the output file\n  and define a macro named  package  with the package name and whose value will\n  replace all occurrences of  ${package}  in the processed code.    -f  or  --docfilter : Filter JavaDoc comments for unused parameters.    --debug : Turn debug mode on.    -h ,  -?  or  --help : Print a short help message and exit.    -v  or  --version : Print version number and exit.    -w  or  --warning : Add a warning on top of the file to prevent editing the\n  result.    -- : Indicate the end of the options.    Some options are clearly targeted at Java code, but TPP can be applied to\nother programming languages.", 
            "title": "Calling the Preprocessor"
        }, 
        {
            "location": "/tpp/#general-syntax", 
            "text": "Pre-processor directives are lines of the form:  //# COMMAND ...  where, to improve readability, there can be any spaces before  // , before and\nafter  # .  In the output, all lines matching this and with a recognized COMMAND  are omitted.  All commands can have and optional comment which is delimited by the first\noccurrence of  //  after the  //# :  //# COMMAND ... // COMMENT  Both  COMMAND  and  COMMENT  may be empty.  Comment lines are a special case\nwith an empty  COMMAND  and empty lines like:  //#  have only spaces (including none) after the  #  and are ignored.", 
            "title": "General Syntax"
        }, 
        {
            "location": "/tpp/#macros", 
            "text": "Macros are pre-processor variables associated with a value.  Every occurrences\nof something like  ${NAME}  in the code will be replaced by the actual value of\nthe macro whose name is  NAME .  It is an error if  NAME  is not a defined\nmacro.  Macro substitution is recursive: all occurrences of  ${...}  are\nreplaced by the corresponding value in the processed file until no other\nsubstitutions are possible.  The name of a macro is case sensitive, it starts\nwith a Latin letter or an underscore character ( a  to  z ,  A  to  Z  or  _ )\nwhich can be followed by any number of Latin letters, underscore characters or\ndigits ( 0  to  9 ).  A macro can be redefined (unless it is one of the read-only macros ) and can be undefined at any time.  It\nis also possible to temporarily suspend and resume substitution of a specific\nmacro.", 
            "title": "Macros"
        }, 
        {
            "location": "/tpp/#simple-macro-definition", 
            "text": "The  def  command defines a macro and takes one of the two following forms:  //# def NAME  = VALUE // COMMENT\n//# def NAME := VALUE // COMMENT  where  NAME  is the name of the macro,  VALUE  specifies the macro value and COMMENT  is an optional comment.  The  VALUE  term may be empty to define the\nmacro to be an empty string.  Spaces after the assignment operator and after\nthe  VALUE  term are ignored.  The two possibilities for (re)defining a macro differ in the processing of the VALUE  term:    If the assignment operator is  = , then all macros are recursively\n  substituted in the  VALUE  term before defining the macro  NAME .    If the assignment operator is  := , then substitutions in the  VALUE  term\n  are deferred until  ${NAME}  is expanded except that occurrences of  ${NAME} \n  in the  VALUE  term are substituted.  This exception is to avoid infinite\n  substitution loops but can be exploited to append or prepend stuff to an\n  existing macro.  This is of interest when a macro is build piece by piece in\n  a loop for instance.  As explained later, this  feature  can also be used to\n   mimic macros with arguments .    Note that contrarily to C preprocessor, overwritting an existing definition is\nnot forbidden.", 
            "title": "Simple Macro Definition"
        }, 
        {
            "location": "/tpp/#evaluate-a-numerical-expression", 
            "text": "A macro can be defined by evaluating a numerical expression with the directive:  //# eval NAME OPER EXPR  where  NAME  is the macro name,  OPER  is an assignment operator and  EXPR  a\nnumerical expression whose value is computed before (re)defining  NAME  via the\noperator.  The expression in  EXPR  is evaluated after recursive macro substitution.  The\nsyntax of the expression is similar to that of the C (in fact it is implemented\nby the  expr  command of Tcl) with a special function  defined(MACRO)  which\nyields  true  or  false  depending whether  MACRO  is a defined macro or not.  The operator  OPER  can be a simple  =  to assign the result of evaluating\nexpression  EXPR  to the macro  NAME  or a composite operator like  OP=  to\nassign to  NAME  the result of the expression  ${NAME} OP (EXPR)  where  OP \ncan be  + ,  - ,  * ,  / ,  % ,   or  .  Example:  //# def a = 1\n//# def b = 4\n//# eval a += ${b}/2  yields a macro named  a  whose value is  3 .  Expressions involve integer arithmetic and tests:   defined(NAME)        check whether macro  NAME  is defined;  ! defined(NAME)      check whether macro  NAME  is not defined;  EXPR1 || EXPR2       logical  or  (with lazzy evaluation);  EXPR1   EXPR2       logical  and  (with lazzy evaluation);  \"text\"               literal text for string comparison;   Note that macros are recursively substituted if they appear in an expression\nincluding whithin the double quotes of a string.", 
            "title": "Evaluate a Numerical Expression"
        }, 
        {
            "location": "/tpp/#predefined-macros", 
            "text": "When processing a file, TPP automatically define (and update) the following\nmacros:   ${__FILE__}  yields the name of the current processed file.  ${__LINE__}  yields the current line number in the processed file.  ${__NEWLINE__}  yields a newline character: \"\\n\".  ${__SPACE__}  yields a single space character: \" \".  ${__COMMENT__}  yields the comment delimiter.  ${}  yields an ordinary dollar sign.   These macros are read-only and cannot be redefined.  Macros can also be defined at the command line with the argument  -Dname=value \nwhere  name  is the name of the macro and  value  its initial value.  There may\nbe as many such definitions in the command line as needed.", 
            "title": "Predefined Macros"
        }, 
        {
            "location": "/tpp/#undefine-macros", 
            "text": "The command:  //# undef NAME1 NAME2 ...  undefines the macros  NAME1 ,  NAME2 , etc.  Until they are redefined, it is an\nerror to expand these macros.  Read-only macros cannot be undefined.\nUndefining a macro which is not defined does nothing.", 
            "title": "Undefine Macros"
        }, 
        {
            "location": "/tpp/#suspend-macro-expansion", 
            "text": "The  #def  directive with the  :=  operator only partially expands the value of\na macro.  While this is sufficient for most of the cases, it is sometimes\nnecessary (or more readable) to temporally suspend the expansion of some\nmacros.  The command:  //# suspend NAME1 NAME2 ...  suspends the expansion of the macros  NAME1 ,  NAME2 , etc.  Until these macros\nare redefined or their expansion resumed with the  #resume  directive, they\nwill not be expanded.  For instance, the expansion of  ${NAME1}  will produce ${NAME1} .  Note that it is not required that a macro be defined prior to\nsuspend its expansion.  As said before, defining a macro (by the  #def  or  #eval  or  #for \ndirectives) resume the expansion of the macro.  This can also be achieved with\nthe following directive:  //# resume NAME1 NAME2 ...", 
            "title": "Suspend Macro Expansion"
        }, 
        {
            "location": "/tpp/#conditional-branching", 
            "text": "A block of code can be processed or not depending on a logical test using the #if  directive and related  #elif  and  #else  directives.  The syntax is as\nfollows (with an arbitrary number, including none, of  #elif  directives and at\nmost one  #else  directive):  //# if EXPR1\nBLOCK1\n//# elif EXPR2\nBLOCK2\n//# else\nBLOCK3\n//# end  where  BLOCK1  is processed if  EXPR1  evaluates to  true , otherwise  BLOCK2 \nis processed if  EXPR2  evaluates to  true , eventually  BLOCK3  is processed\nif neither  EXPR1  nor  EXPR2  evaluate to  true .  Conditional expressions are\nevaluated using the same rules as in the  #eval  directive.", 
            "title": "Conditional Branching"
        }, 
        {
            "location": "/tpp/#loops", 
            "text": "A distinctive feature of TPP is to provide loops which may be embedded in other\nloops to an arbitrarily level.  There are two kinds of loops:  for -loops and while -loops.  The syntax of a  for -loop is:  //# for NAME in EXPR\n...\n//# end  where  EXPR  is everything after the  in  keyword and up to the end of line or\nto the  //  of the optional comment.  After macro substitution of the  EXPR \nterm, it is interpreted either as a list of values separated by spaces or as a\nrange.  The macro  NAME  will successively takes the different values of the\nlist or of the range and the body of the loop (that is code up to the matching end  keyword) will be processed.  If, after macro substitutions, the value of EXPR  is an empty list or an empty range, the the body of the loop is just\nskipped.  A range of values has the form:  FIRST : LAST  or  FIRST : LAST : STEP  where (after macro expansion)  FIRST ,  LAST  and  STEP  are integers, if\nomitted,  STEP  is assumed to be  1 .  A zero- STEP  is forbidden.  Numerical\nexpressions are not yet supported for these fields but you can use the  #eval \ndirective to compute the range parameters.  For instance:  //# eval last = ${x} + 3*${y}\n//# for i in 0 : ${last} // main loop\n...\n//# end // end of main loop  Here is another example with a list of values:  //# def list = blue red yellow orange\n//# for var in ${list}\n//#     emit ${var}\n//# end  where the directive  #emit  directive emits its argument(s) in the output code.  The syntax of  while -loops is:  //# while EXPR\n...\n//# end  which results in processing the boby of the loop until  EXPR  expands to a\nfalse value.  The two following loops are similar (the second being more concise):  //# def body := dim${k} = ${k}; // the code to expand\n//# def k = 4\n//# while ${k}   12\n${boby}\n//#     eval k += 3\n//# end\n\n//# def body := dim${k} = ${k};\n//# for k in 4:12:3\n${body}\n//# end  they both produce:  dim4 = 4\ndim7 = 7\ndim10 = 10  Note how the expansion of  ${k}  is deferred by using operator  :=  to define\nmacro  body .", 
            "title": "Loops"
        }, 
        {
            "location": "/tpp/#include-another-source-file", 
            "text": "The contents of another source file can be processed at any place by using the #include  directive:  //# include WHAT  where  WHAT  (after recursive macro expansion) takes one of the two forms: FILENAME  or  \"FILENAME\" .  The result is as if the contents of the file FILENAME  be inserted in place of the command.  A restriction is that\ndirectives operating on blocks ( #if ... ,  #for ...  and  #while ... ) must\nbe open and closed in a single included file.", 
            "title": "Include Another Source File"
        }, 
        {
            "location": "/tpp/#emitting-code-or-printing-messages", 
            "text": "The command:  //# emit CODE  substitutes macros in  CODE  and prints it to the output file.  Commands:  //# echo MESG\n//# warn MESG  substitute macros in  MESG  and print it.  Command  #echo  uses the standard\noutput stream while  #warn  uses the standard error stream.  It may be useful to examine the contents of some macros (without a fully\nrecursive expansion).  To that end, the directive  //# debug MESG  prints  MESG  after a  single round  of macro substitution on the standard error\nstream.  The  #error  command:  //# error MESG  substitutes macros in  MESG  and prints it on the standard error stream with\nthe line number and the name of the processed file and then aborts the\nprocessing.", 
            "title": "Emitting Code or Printing Messages"
        }, 
        {
            "location": "/tpp/#examples", 
            "text": "", 
            "title": "Examples"
        }, 
        {
            "location": "/tpp/#variable-length-lists", 
            "text": "The following example builds a list of dimensions:  //# def dims =  // start with an empty list\n//# def sep  =  // and an empty separator\n//# for k in 1 : ${rank}\n//#     def dims = ${dims}${sep}dim${k}\n//#     def sep = ,${__SPACE__}\n//# end  and yields a macro named  dims  with contents  dim1, dim2, ... .  Note the use\nof an auxiliary macro  sep  and of the predefined macro  __SPACE__  to nicely\nseparate the elements of the list.  Another possibility is to write:  //# if ${rank}   1\n//#     def dims =  // result is an empty list\n//# else\n//#     def dims = dim1 // initial list\n//#     for k in 2 : ${rank}\n//#         def dims = ${dims}, dim${k}\n//#     end\n//# end", 
            "title": "Variable Length Lists"
        }, 
        {
            "location": "/tpp/#macros-as-pseudo-functions", 
            "text": "Deferred substitution can be used as follows:  //# def list := ${prefix}1\n//# for k in 2 : 3\n//#     def list := ${list},${prefix}${k}\n//# end  which yields a macro  list  whose contents is ${prefix}1,${prefix}2,${prefix}3 .  Note that, at this stage,  prefix  does\nnot need to be defined.  The macro  list  can then be used as a template to\nmake lists after substitution of the  prefix  macro:  //# def prefix  = foo\n//# def FooList = ${list}\n//# def prefix  = bar\n//# def BarList = ${list}  \nwhich yields `foo1,foo2,foo3` and `bar1,bar2,bar3` for the respective contents\nof macros `FooList` and `BarList`.\n\nWith this kind of trick it is also possible to mimic the behavior of\nmacros with arguments (even though it is less readable).\n\nTo build the macro `list` above, we may also suspend the expansion of the macro\n`prefix`:\n\n```java\n//# suspend prefix\n//# def list = ${prefix}1\n//# for k in 2 : 3\n//#     def list = ${list},${prefix}${k}\n//# end  As (re)defining  prefix  will automatically resume macro expansion, it is not\nnecessary to have a  #resume prefix  command.", 
            "title": "Macros as Pseudo-Functions"
        }, 
        {
            "location": "/tpp/#index-of-directives", 
            "text": "//  comment;    #debug  print a debug message;    #def  define a macro;    #echo  print a message to the\n  standard output stream;    #elif  conditional branching;    #else  conditional branching;    #emit  write some code to the result;    #end  mark the end of a loop or of a conditional\n  branching;    #error  output an error message and\n  exit;    #eval  evaluate a numerical expression;    #for  loop with a macro taking different values;    #if  conditional branching;    #include  include the contents of another\n  file;    #resume  resume macro expansion;    #suspend  suspend macro expansion;    #undef  undefine a macro;    #warn  print a message to the\n  standard error stream;    #while  conditional loop;", 
            "title": "Index of Directives"
        }, 
        {
            "location": "/tpp/#future-evolution", 
            "text": "It may be useful to customize the syntax in order to accomodate to\n   various programming languages.  For instance:    @name@        to interpolate a macro;   @@            for a single  @ ;   #@ COMMAND    for preprocessor directives;    Macros with arguments (spaces stripped):  ${macro(arg1,arg2,...)}    String functions (like predefined macros).    ${substr(str,i1,i2,subs)}\n${strmatch(string,pattern)}\n...   Allow for numerical expressions in ranges (taking care of the ternary\n   operator).", 
            "title": "Future Evolution"
        }, 
        {
            "location": "/deconv-tool/", 
            "text": "Deblurring/denoising of images with edge preserving\n\n\nAs a demonstration, TiPi provides a command line tool \ntipideconv\n for the\ndeblurring/denoising of images.  This tool avoids border artifacts, implements\nedge-preserving regularization, accounts for bad/missing data and constraints\nsuch as nonnegativity.\n\n\nInverse problem\n\n\nThe principle of \ntipideconv\n is to solve the following inverse problem:\n\n\n\n    min { f(x) = f\ndata\n(x) + \u00b5 f\nprior\n(x) }\n\n\n\n\nwhere \nx\n is the solution (\ne.g.\n the deblurred/denoised image) and \nf(x)\n is\nthe objective function to minimize.  The objective function is specified by\n\nf\ndata\n(x)\n, the \nlikelihood\n term, which imposes to fit\nthe data, \nf\nprior\n(x)\n, the \nregularization\n term, which\nimposes prior knowledge about \nx\n and \n\u00b5 \u2265 0\n which tune the relative\nimportance of the regularization.  Minimizing \nf(x)\n can be seen as seeking for\n\nx\n which is compromise between good fit to the data and agreement with some\npriors.\n\n\nThe likelihood term is defined as:\n\n\n\n    f\ndata\n(x) = (1/2) \u2225h*x - y\u2225\n2\nW\n\n\n\n\n\nwith \nh\n the point spread function (PSF), \nh*x\n the convolution of the image\n\nx\n by \nh\n, \ny\n the data and \nW = diag(w)\n a diagonal weighting operator.  The\n(squared) weighted norm is given by \n\u2225u\u2225\n2\nW\n =\nu\nt\n\u22c5W\u22c5u\n\n\nThe regularization favors egde-preserving smoothness, it is given by:\n\n\n\n    f\nprior\n(x) = \u2211\n i\n\n    sqrt( \u2225(\u2207x)\ni\n\u2225\n2\n + \u03b5\n2\n )\n\n\n\n\nwhere \n\u2225(\u2207x)\ni\n\u2225\n is the Euclidean norm of the spatial\ngradient at position \ni\n and \n\u03b5\n is an edge threshold parameter.  The\nsmoothness is less severely imposed where the spatial gradient is larger than\nthis threshold which should be set to the typical height of the edges.\n\n\nThe quantities \ny\n, \nh\n, \nw\n, \n\u00b5\n and \n\u03b5\n are all input parameters of\n\ntipideconv\n.  If the PSF \nh\n is not specified, it is assumed to be a Dirac\ndelta function thus no attempt to deblur the image is done and the result of\nthe inverse problem is a denoised image.\n\n\nSimple usage\n\n\nThe command line tool is typically called as:\n\n\njava -jar TiPi.jar [OPTIONS] INPUT OUTPUT\n\n\n\nwhere \nTiPi.jar\n is the launchable JAR file of TiPi, \nOPTIONS\n represent\noptional settings, \nINPUT\n is the name of the file with the input image (or\ndata) \ny\n and \nOUTPUT\n is the name of the file to save the result \nx\n. All\nfiles are identified by their extension (at least FITS and MDA format are\nsupported).\n\n\nThe most common options are:\n\n\n\n\n\n\n--psf NAME\n to specify the name of the file with the PSF \nh\n.  If not\n  specified, a Dirac delta function is assumed (\ni.e.\n no deblurring).\n\n\n\n\n\n\n--mu \u00b5\n to specify the regularization level.\n\n\n\n\n\n\n--epsilon \u03b5\n to specify the edge threshold.\n\n\n\n\n\n\nThere are many other options which are described in the following sections.\nMost parameters have default values.  All parameters (and their default values)\ncan be displayed with:\n\n\ntipideconv --help\n\n\n\nInitial solution\n\n\nThe image restoration is an iterative process.  By default, the initial image\nhas the same value everywhere.  Another initial image may be provided with the\noption \n--init FILENAME\n where \nFILENAME\n is the name of the file with the\nimage to start with.  Although the solution of the inverse problem is unique\n(provided \n\u00b5 \n 0\n), this option is useful to speedup computations by starting\nthe algorithm with a better approximation of the solution than the default\ninitial image.  This is of particular importance when tuning the parameters\n(\ne.g.\n \n\u00b5\n and \n\u03b5\n) which have an influence on the solution.\n\n\nWeighting of the data\n\n\nBy default, the data noise is assumed to be i.i.d. (independent and identically\ndistributed) with a normal distribution.  This amounts to having a simple\nsquared Euclidean norm for the data agreement term\n\nf\ndata\n(x)\n, \ni.e.\n the weighting operator is equal to the\nidentity, \nW = I\n.  There are however options to specify other weights \nw\n and\nassume that the data noise distribution is approximately independent and\nGaussian but not necessarily identically distributed.\n\n\nOption \n--weights FILENAME\n where \nFILENAME\n is the name of a file with the\nweights to use is the most flexible way to specify the weights \nw\n.  Note that\nthe weights \nw\n must have the same dimensions as the data \ny\n (\ni.e.\n one\nweight per piece of data) and that all weights must be finite and nonnegative.\n\n\nAnother possibility is to use options \n--noise SIGMA\n and \n--gain GAMMA\n\nto compute the weights using a simple model of the variance of the data:\n\n\n\n\n\n\nIf only \n--noise SIGMA\n is specified, it is assumed that \nSIGMA\n is the\n standard deviation of the noise in the same units as the data for each\n measurement. \nSIGMA\n must be strictly positive.\n\n\n\n\n\n\nIf \n--noise SIGMA\n and \n--gain GAMMA\n are both specified, it is assumed that\n  \nSIGMA\n is the standard deviation of the readout noise in counts (\ne.g.\n\n  photo-electrons) per measurement while \nGAMMA\n is the conversion factor in\n  counts per analog digital unit (ADU) such that \nGAMMA\u22c5y\n is the measured\n  data in count units.\n\n\n\n\n\n\nNote that option \n--weights\n has precedence over \n--noise\n and \n--gain\n, the\ntwo latter options are ignored if \n--weights\n is specified.  In neither\n\n--noise\n, nor \n--gain\n, nor \n--weights\n are specified, a simple least-squares\nnorm is used for the data agreement term.\n\n\nInvalid data and avoiding border artifacts\n\n\nOne of the important feature of \ntipideconv\n is to properly take into account\nmissing or invalid data.  This however necessitates to properly specify where\nare the invalid measurements.\n\n\nIn the input data, all non-finite values are assumed to be invalid and will not\nbe considered by the processing.  Furthermore, if weights are specified (via\nthe \n--weights\n option), any piece of data whose corresponding weight is zero\nis also not considered.\n\n\nThis behavior can be combined with the option \n--invalid FILENAME\n to specify\nthe name of a data file with the same dimensions as the input data and whose\nvalues are non-zero where the data should be discarded.\n\n\nTo avoid aliasing and the resulting border artifacts, \ntipideconv\n is capable\nof restoring an image which is larger than the original data.  Option \n--pad\n\ncan be used to control the amount of padding, its value can be \nauto\n (to avoid\naliasing almost completely), \nmin\n to work with the minimal possible size, or a\nnumber \nn\n to pad by at least \nn\n elements along all dimensions.  In addition\nto this padding, the dimensions may be enlarged to achieve faster operations\n(because of the FFT).  Option \n--crop\n can be specified to remove the extra\npadding in the saved solution.\n\n\nBound constraints\n\n\nOptions \n--min LOWER\n and \n--max UPPER\n may be used to specify a lower and an\nupper bounds for the result.  For instance, \n--min 0\n would enforce\nnonnegativity of the result.  Note that when any bound is specified, the\noptimization method is automatically set to be a variant of the limited memory\nBGFS method with bound constraints.\n\n\nTuning the optimizer\n\n\nA limited memory optimizer is in charge of solving the inverse problem.  The\nnumber of memorized steps can be specified with option \n--lbfgs NUMBER\n.  If\n\nNUMBER\n is less or equal zero and if there are no bound constraints on the\nvariables, then a non-linear conjugate gradient algorithm is used; otherwise, a\nlimited memory quasi-Newton method (similar to L-BFGS) is used.  The number of\nmemorized steps has only an incidence on the computation time, a moderate\nnumber of memorized steps is usually a good compromise to achieve the least\nnumber of iterations while keeping each iteration not too expensive to compute\nand the amount of memory reasonable.  For very large problems, you may have to\ntake \nNUMBER = 1\n or \nNUMBER = 0\n to keep the memory requirements as low as\npossible.  You may also tune the parameters of the \njava\n command to allocate\nmore memory to the Java virtual machine (in the limits of your machine memory of\ncourse).\n\n\nAnother way to limit the amount of memory (and to speedup the computations) is\nto force the algorithm to use single precision floating point values by\nspecifying option \n--single\n.  By default, single precision is used if all\ninputs files use integers or single precision floating point values.\n\n\nThe convergence criterion is based on the Euclidean norm of the gradient of the\nobjective function (or on the infinite norm of the gradient if there are bound\nconstraints).  The convergence of the algorithm is assumed as soon as:\n\n\n\n    \u2225\u2207f(x)\u2225 \u2264 max( gatol, grtol\u22c5\u2225\u2207f(x\n0\n)\u2225 )\n\n\n\n\nwhere \nx\n0\n is the initial solution and \ngatol\n and\n\ngrtol\n are the absolute and relative gradient tolerances.  Both can be\nspecified by the options \n--gatol VALUE\n and \n--grtol VALUE\n.\n\n\nIt is possible to limit the number of iterations of the algorithm and/or the\nnumber of evaluations of the cost function respectively via the options\n\n--maxiter NUMBER\n and \n--maxeval NUMBER\n.  Note that at least one function\n(and gradient) evaluation per iteration is required.", 
            "title": "Tools"
        }, 
        {
            "location": "/deconv-tool/#deblurringdenoising-of-images-with-edge-preserving", 
            "text": "As a demonstration, TiPi provides a command line tool  tipideconv  for the\ndeblurring/denoising of images.  This tool avoids border artifacts, implements\nedge-preserving regularization, accounts for bad/missing data and constraints\nsuch as nonnegativity.", 
            "title": "Deblurring/denoising of images with edge preserving"
        }, 
        {
            "location": "/deconv-tool/#inverse-problem", 
            "text": "The principle of  tipideconv  is to solve the following inverse problem:  \n    min { f(x) = f data (x) + \u00b5 f prior (x) }  where  x  is the solution ( e.g.  the deblurred/denoised image) and  f(x)  is\nthe objective function to minimize.  The objective function is specified by f data (x) , the  likelihood  term, which imposes to fit\nthe data,  f prior (x) , the  regularization  term, which\nimposes prior knowledge about  x  and  \u00b5 \u2265 0  which tune the relative\nimportance of the regularization.  Minimizing  f(x)  can be seen as seeking for x  which is compromise between good fit to the data and agreement with some\npriors.  The likelihood term is defined as:  \n    f data (x) = (1/2) \u2225h*x - y\u2225 2 W   with  h  the point spread function (PSF),  h*x  the convolution of the image x  by  h ,  y  the data and  W = diag(w)  a diagonal weighting operator.  The\n(squared) weighted norm is given by  \u2225u\u2225 2 W  =\nu t \u22c5W\u22c5u  The regularization favors egde-preserving smoothness, it is given by:  \n    f prior (x) = \u2211  i \n    sqrt( \u2225(\u2207x) i \u2225 2  + \u03b5 2  )  where  \u2225(\u2207x) i \u2225  is the Euclidean norm of the spatial\ngradient at position  i  and  \u03b5  is an edge threshold parameter.  The\nsmoothness is less severely imposed where the spatial gradient is larger than\nthis threshold which should be set to the typical height of the edges.  The quantities  y ,  h ,  w ,  \u00b5  and  \u03b5  are all input parameters of tipideconv .  If the PSF  h  is not specified, it is assumed to be a Dirac\ndelta function thus no attempt to deblur the image is done and the result of\nthe inverse problem is a denoised image.", 
            "title": "Inverse problem"
        }, 
        {
            "location": "/deconv-tool/#simple-usage", 
            "text": "The command line tool is typically called as:  java -jar TiPi.jar [OPTIONS] INPUT OUTPUT  where  TiPi.jar  is the launchable JAR file of TiPi,  OPTIONS  represent\noptional settings,  INPUT  is the name of the file with the input image (or\ndata)  y  and  OUTPUT  is the name of the file to save the result  x . All\nfiles are identified by their extension (at least FITS and MDA format are\nsupported).  The most common options are:    --psf NAME  to specify the name of the file with the PSF  h .  If not\n  specified, a Dirac delta function is assumed ( i.e.  no deblurring).    --mu \u00b5  to specify the regularization level.    --epsilon \u03b5  to specify the edge threshold.    There are many other options which are described in the following sections.\nMost parameters have default values.  All parameters (and their default values)\ncan be displayed with:  tipideconv --help", 
            "title": "Simple usage"
        }, 
        {
            "location": "/deconv-tool/#initial-solution", 
            "text": "The image restoration is an iterative process.  By default, the initial image\nhas the same value everywhere.  Another initial image may be provided with the\noption  --init FILENAME  where  FILENAME  is the name of the file with the\nimage to start with.  Although the solution of the inverse problem is unique\n(provided  \u00b5   0 ), this option is useful to speedup computations by starting\nthe algorithm with a better approximation of the solution than the default\ninitial image.  This is of particular importance when tuning the parameters\n( e.g.   \u00b5  and  \u03b5 ) which have an influence on the solution.", 
            "title": "Initial solution"
        }, 
        {
            "location": "/deconv-tool/#weighting-of-the-data", 
            "text": "By default, the data noise is assumed to be i.i.d. (independent and identically\ndistributed) with a normal distribution.  This amounts to having a simple\nsquared Euclidean norm for the data agreement term f data (x) ,  i.e.  the weighting operator is equal to the\nidentity,  W = I .  There are however options to specify other weights  w  and\nassume that the data noise distribution is approximately independent and\nGaussian but not necessarily identically distributed.  Option  --weights FILENAME  where  FILENAME  is the name of a file with the\nweights to use is the most flexible way to specify the weights  w .  Note that\nthe weights  w  must have the same dimensions as the data  y  ( i.e.  one\nweight per piece of data) and that all weights must be finite and nonnegative.  Another possibility is to use options  --noise SIGMA  and  --gain GAMMA \nto compute the weights using a simple model of the variance of the data:    If only  --noise SIGMA  is specified, it is assumed that  SIGMA  is the\n standard deviation of the noise in the same units as the data for each\n measurement.  SIGMA  must be strictly positive.    If  --noise SIGMA  and  --gain GAMMA  are both specified, it is assumed that\n   SIGMA  is the standard deviation of the readout noise in counts ( e.g. \n  photo-electrons) per measurement while  GAMMA  is the conversion factor in\n  counts per analog digital unit (ADU) such that  GAMMA\u22c5y  is the measured\n  data in count units.    Note that option  --weights  has precedence over  --noise  and  --gain , the\ntwo latter options are ignored if  --weights  is specified.  In neither --noise , nor  --gain , nor  --weights  are specified, a simple least-squares\nnorm is used for the data agreement term.", 
            "title": "Weighting of the data"
        }, 
        {
            "location": "/deconv-tool/#invalid-data-and-avoiding-border-artifacts", 
            "text": "One of the important feature of  tipideconv  is to properly take into account\nmissing or invalid data.  This however necessitates to properly specify where\nare the invalid measurements.  In the input data, all non-finite values are assumed to be invalid and will not\nbe considered by the processing.  Furthermore, if weights are specified (via\nthe  --weights  option), any piece of data whose corresponding weight is zero\nis also not considered.  This behavior can be combined with the option  --invalid FILENAME  to specify\nthe name of a data file with the same dimensions as the input data and whose\nvalues are non-zero where the data should be discarded.  To avoid aliasing and the resulting border artifacts,  tipideconv  is capable\nof restoring an image which is larger than the original data.  Option  --pad \ncan be used to control the amount of padding, its value can be  auto  (to avoid\naliasing almost completely),  min  to work with the minimal possible size, or a\nnumber  n  to pad by at least  n  elements along all dimensions.  In addition\nto this padding, the dimensions may be enlarged to achieve faster operations\n(because of the FFT).  Option  --crop  can be specified to remove the extra\npadding in the saved solution.", 
            "title": "Invalid data and avoiding border artifacts"
        }, 
        {
            "location": "/deconv-tool/#bound-constraints", 
            "text": "Options  --min LOWER  and  --max UPPER  may be used to specify a lower and an\nupper bounds for the result.  For instance,  --min 0  would enforce\nnonnegativity of the result.  Note that when any bound is specified, the\noptimization method is automatically set to be a variant of the limited memory\nBGFS method with bound constraints.", 
            "title": "Bound constraints"
        }, 
        {
            "location": "/deconv-tool/#tuning-the-optimizer", 
            "text": "A limited memory optimizer is in charge of solving the inverse problem.  The\nnumber of memorized steps can be specified with option  --lbfgs NUMBER .  If NUMBER  is less or equal zero and if there are no bound constraints on the\nvariables, then a non-linear conjugate gradient algorithm is used; otherwise, a\nlimited memory quasi-Newton method (similar to L-BFGS) is used.  The number of\nmemorized steps has only an incidence on the computation time, a moderate\nnumber of memorized steps is usually a good compromise to achieve the least\nnumber of iterations while keeping each iteration not too expensive to compute\nand the amount of memory reasonable.  For very large problems, you may have to\ntake  NUMBER = 1  or  NUMBER = 0  to keep the memory requirements as low as\npossible.  You may also tune the parameters of the  java  command to allocate\nmore memory to the Java virtual machine (in the limits of your machine memory of\ncourse).  Another way to limit the amount of memory (and to speedup the computations) is\nto force the algorithm to use single precision floating point values by\nspecifying option  --single .  By default, single precision is used if all\ninputs files use integers or single precision floating point values.  The convergence criterion is based on the Euclidean norm of the gradient of the\nobjective function (or on the infinite norm of the gradient if there are bound\nconstraints).  The convergence of the algorithm is assumed as soon as:  \n    \u2225\u2207f(x)\u2225 \u2264 max( gatol, grtol\u22c5\u2225\u2207f(x 0 )\u2225 )  where  x 0  is the initial solution and  gatol  and grtol  are the absolute and relative gradient tolerances.  Both can be\nspecified by the options  --gatol VALUE  and  --grtol VALUE .  It is possible to limit the number of iterations of the algorithm and/or the\nnumber of evaluations of the cost function respectively via the options --maxiter NUMBER  and  --maxeval NUMBER .  Note that at least one function\n(and gradient) evaluation per iteration is required.", 
            "title": "Tuning the optimizer"
        }, 
        {
            "location": "/license/", 
            "text": "TiPi is released under the MIT License:\n\n\n\n\nCopyright (c) 2014 the MiTiV project, http://mitiv.univ-lyon1.fr/\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.", 
            "title": "License"
        }, 
        {
            "location": "/news/", 
            "text": "2016/../..\n\n\n\n\n\n\nDeconvolution works in single/double precision.\n\n\n\n\n\n\nDeconvolution no longer zero-pad the data.\n\n\n\n\n\n\nImproved line search parameters.\n\n\n\n\n\n\n\"Step changed\" bug fixed.\n\n\n\n\n\n\nAdd \nisFlat\n method for checking whether the array is already in a\n    \nflat\n form.  Methods \nflatten()\n and \nisFlat()\n are more consistent.\n    Some methods has been optimized to account for flat arrays.\n\n\n\n\n\n\nSpeed up deconvolution by not zero-padding the data (but still use a\n    larger object space to avoid border artifacts).\n\n\n\n\n\n\nDuplicated methods between \nVectorSpace\n and \nVector\n have been removed.\n    the low level methods are kept in the \nVectorSpace\n class and all high\n    level methods which involve at least a vector are now provided in the\n    \nVector\n class.  This yields more readable and consistent code.\n\n\n\n\n\n\nbyte\n type in shaped arrays is assumed to be unsigned as it makes more\n    sense for image processing.  This involves expressions like \n(b \n 0xFF)\n\n    when using byte value \nb\n.\n\n\n\n\n\n\n2014/11/04\n\n\n\n\n\n\nRelease 0.1.1\n\n\n\n\n2014/11/04\n\n\n\n\nRelease 0.1.0", 
            "title": "News"
        }
    ]
}